---
description: 
globs: 
alwaysApply: true
---
# PenPal Plugin System Guide

PenPal uses a sophisticated plugin architecture that allows dynamic loading of cybersecurity tools and integrations.

## Plugin Loading System
- **Server Plugin Loader**: [Plugins/plugins-loader-server.js](mdc:Plugins/plugins-loader-server.js)
- **Client Plugin Loader**: [Plugins/plugins-loader-client.js](mdc:Plugins/plugins-loader-client.js)
- **Plugin Development Script**: [penpal-plugin-develop.py](mdc:penpal-plugin-develop.py)

## Core Plugins
- **Base Plugin**: [Plugins/Base/server/manifest.json](mdc:Plugins/Base/server/manifest.json) - Foundation plugin
- **CoreAPI Plugin**: [Plugins/CoreAPI/server/manifest.json](mdc:Plugins/CoreAPI/server/manifest.json) - Data standardization
- **DataStore Plugin**: [Plugins/DataStore/server/plugin.js](mdc:Plugins/DataStore/server/plugin.js) - Data abstraction layer
- **MongoDB Adapter**: [Plugins/DataStoreMongoAdapter/server/plugin.js](mdc:Plugins/DataStoreMongoAdapter/server/plugin.js)
- **JobsTracker Plugin**: [Plugins/JobsTracker/server/plugin.js](mdc:Plugins/JobsTracker/server/plugin.js) - Centralized job management
- **Docker Plugin**: [Plugins/Docker/server/plugin.js](mdc:Plugins/Docker/server/plugin.js) - Container orchestration

## Plugin Structure Requirements
Each plugin must have:
1. **manifest.json** - Plugin metadata, dependencies, and versioning
2. **index.js** - Plugin registration with PenPal core
3. **plugin.js** - Plugin implementation and GraphQL integration
4. **install-dependencies.sh** (optional) - Custom dependency installation
5. **docker-context/** (optional) - Docker build context for containerized tools

## Security Tool Plugins
- **Nmap**: [Plugins/Nmap/server/plugin.js](mdc:Plugins/Nmap/server/plugin.js) - Network scanning
- **Rustscan**: [Plugins/Rustscan/server/plugin.js](mdc:Plugins/Rustscan/server/plugin.js) - Fast port scanning
- **HttpX**: [Plugins/HttpX/server/plugin.js](mdc:Plugins/HttpX/server/plugin.js) - HTTP service discovery

## Plugin Development Template
Use [PluginTemplate/](mdc:PluginTemplate) as a starting point for new plugins.

## Plugin Communication
- **MQTT Plugin**: [Plugins/MQTT/server/plugin.js](mdc:Plugins/MQTT/server/plugin.js) - Inter-plugin messaging
- Plugins can subscribe to events like new hosts/networks discovery
- Job queue system for long-running tasks

## Docker Plugin - Container Orchestration

**✅ CRITICAL: Docker Plugin for Microservices**
The Docker plugin provides essential container orchestration capabilities for running cybersecurity tools in isolated environments. It's fundamental for plugins like Nmap, HttpX, and other security tools.

### Docker Plugin Configuration

**Docker Settings in plugin.js:**
```javascript
// ✅ CORRECT Docker configuration patterns
export const settings = {
  docker: {
    name: "penpal:toolname",                    // Container image name
    dockercontext: `${__dirname}/docker-context`, // Build context path
    // OR for pre-built images:
    // image: "existing/image:tag"              // Pull existing image
  },
};

// ❌ WRONG - Don't mix image and dockerfile/dockercontext
export const settings = {
  docker: {
    name: "penpal:toolname",
    dockercontext: "./docker-context",
    image: "conflicting/image"  // Causes validation error
  },
};
```

### Docker API Methods

**Container Lifecycle Management:**
```javascript
// ✅ Run containers with proper isolation
const result = await PenPal.Docker.Run({
  image: "penpal:httpx",
  cmd: "httpx -l /input/targets.txt -o /output/results.json",
  daemonize: true,                    // Run in background
  network: "penpal_penpal",          // Use PenPal network
  volume: {                          // Mount shared volume
    name: "penpal_penpal-plugin-share",
    path: "/penpal-plugin-share"
  }
});

// Get container ID and wait for completion
const container_id = result.stdout.trim();
await PenPal.Docker.Wait(container_id);
```

**Volume Management:**
```javascript
// ✅ CORRECT Volume patterns for file I/O
const volume = {
  name: "penpal_penpal-plugin-share",  // Shared volume name
  path: "/penpal-plugin-share"         // Container mount path
};

// Use volume paths that work with mounts
const host_file = "/penpal-plugin-share/httpx/project1/targets.txt";
const container_file = host_file.replace("/penpal-plugin-share", "/penpal-plugin-share");

// ❌ WRONG - Don't use hardcoded paths
const bad_path = "/tmp/local-file.txt";  // Won't be accessible in container
```

**Container Commands:**
```javascript
// Available Docker operations
await PenPal.Docker.Start(container_id);           // Start stopped container
await PenPal.Docker.Stop(container_id);            // Stop running container
await PenPal.Docker.Wait(container_id);            // Wait for completion
await PenPal.Docker.Exec({ container, cmd });      // Execute in running container
await PenPal.Docker.Copy({ container, container_file, output_file }); // Copy files
await PenPal.Docker.RemoveContainer(container_id); // Clean up container
await PenPal.Docker.Raw(docker_command);           // Execute raw docker command
```

### Docker Build Process

**✅ CRITICAL: Background Image Building**
The Docker plugin builds images in the background during startup to avoid blocking server initialization. This allows the GraphQL server to start immediately while Docker builds happen asynchronously.

```javascript
// Docker plugin validates settings and builds images
const check_docker = (docker) => {
  // Validates docker configuration
  // Ensures either image OR dockerfile/dockercontext is specified
  // Checks for required fields (name, etc.)
};

const build_docker_images = async () => {
  // Returns immediately to not block startup
  // Starts background building process
  // Images tracked with Jobs API for progress monitoring
};
```

**Background Build Status Tracking:**
```javascript
// ✅ Check if Docker images are ready before using them
if (PenPal.Docker.IsImageReady("penpal:httpx")) {
  // Image is built and ready to use
  await performContainerizedScan();
} else if (PenPal.Docker.IsImageBuilding("penpal:httpx")) {
  // Image is currently building in background
  console.log("Waiting for Docker image to build...");
} else if (PenPal.Docker.IsImageFailed("penpal:httpx")) {
  // Image build failed
  console.error("Docker image build failed");
}

// ✅ RECOMMENDED: Use helper function to wait for image readiness
await PenPal.Docker.WaitForImageReady("penpal:httpx", {
  updateCallback: update_job, // Optional progress callback
  updateMessage: "Waiting for HttpX Docker image to build...",
  timeout: 120000 // Optional timeout in ms (default: 2 minutes)
});

// Get complete build status
const buildStatus = PenPal.Docker.GetBuildStatus();
console.log("Pending builds:", buildStatus.pending);
console.log("Currently building:", buildStatus.building);
console.log("Completed builds:", buildStatus.completed);
console.log("Failed builds:", buildStatus.failed);
```

**Background Build Benefits:**
- **Faster Server Startup**: GraphQL server starts immediately
- **Non-blocking**: Long Docker builds don't delay application availability
- **Progress Tracking**: All builds tracked as Jobs with real-time progress
- **Parallel Building**: Multiple images build simultaneously
- **Error Handling**: Failed builds don't crash the server

**Dockerfile Best Practices:**
```dockerfile
# ✅ Multi-stage builds for security tools
FROM golang:1.21-alpine AS builder
WORKDIR /app
RUN go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /go/bin/httpx .
ENTRYPOINT ["./httpx"]
```

### Integration Patterns

**MQTT-Triggered Container Execution:**
```javascript
// ✅ Standard pattern for event-driven security tools
const HttpXPlugin = {
  async loadPlugin() {
    const MQTT = await PenPal.MQTT.NewClient();
    
    // Subscribe to service discovery events
    await MQTT.Subscribe(
      PenPal.API.MQTT.Topics.New.Services,
      async ({ project, service_ids }) => {
        // Filter services for HTTP scanning candidates
        const services = await PenPal.API.Services.GetMany(service_ids);
        const tcp_services = services.filter(s => 
          s.ip_protocol === "TCP" && s.status === "open"
        );
        
        if (tcp_services.length > 0) {
          await performContainerizedScan(tcp_services);
        }
      }
    );
    
    return { settings };
  },
};
```

**File-Based Container Communication:**
```javascript
// ✅ Use shared volumes for input/output
export const performHttpScan = async ({ services, project_id }) => {
  const outdir = "/penpal-plugin-share/httpx/" + project_id;
  PenPal.Utils.MkdirP(outdir);
  
  // Create input file for container
  const targets_file = path.join(outdir, `targets-${PenPal.Utils.Epoch()}.txt`);
  const targets = services.map(s => `http://${s.host_ip}:${s.port}`);
  fs.writeFileSync(targets_file, targets.join('\n'));
  
  // Create output file path
  const output_file = path.join(outdir, `results-${PenPal.Utils.Epoch()}.json`);
  
  // Convert to container paths
  const container_targets = targets_file.replace("/penpal-plugin-share", "/penpal-plugin-share");
  const container_output = output_file.replace("/penpal-plugin-share", "/penpal-plugin-share");
  
  // Run containerized tool
  const result = await PenPal.Docker.Run({
    image: settings.docker.name,
    cmd: `-l ${container_targets} -o ${container_output} -json`,
    daemonize: true,
    volume: { name: "penpal_penpal-plugin-share", path: "/penpal-plugin-share" },
    network: "penpal_penpal"
  });
  
  // Wait and process results
  await PenPal.Docker.Wait(result.stdout.trim());
  const results = fs.readFileSync(output_file, 'utf8');
  return JSON.parse(results);
};
```

### Security and Isolation

**Network Isolation:**
- All containers run in `penpal_penpal` network
- Isolated from host network by default
- Can communicate with other PenPal services

**Volume Security:**
- Shared volumes use specific mount points
- No access to host filesystem outside mounted volumes
- Temporary files automatically cleaned up

**Resource Management:**
- Containers are ephemeral and cleaned up after use
- No persistent state in containers
- Resource limits can be enforced

### Docker Plugin Dependencies

**Required Dependencies:**
```json
{
  "name": "YourSecurityTool",
  "dependsOn": ["CoreAPI@0.1.0", "Docker@0.1.0", "JobsTracker@0.1.0"]
}
```

**Docker Host Configuration:**
- Requires Docker daemon accessible at `penpal-docker-api:2376`
- Uses Docker Compose for orchestration
- Supports both image pulling and local building

## Jobs API - Centralized Job Management

The **JobsTracker Plugin** provides a centralized job management system for long-running tasks across all plugins. This replaces the need for individual plugins to manage their own job queues.

### Jobs API Usage

**✅ CRITICAL: Jobs API Signature**
All Jobs operations are available through the `PenPal.Jobs` object:

```javascript
// ✅ CORRECT Jobs API usage
const job = await PenPal.Jobs.Create(jobData);
await PenPal.Jobs.Update(job_id, updates);
await PenPal.Jobs.UpdateProgress(job_id, progress);
await PenPal.Jobs.UpdateStage(job_id, stage_index, updates);
const job = await PenPal.Jobs.Get(job_id);
const jobs = await PenPal.Jobs.GetAll();
const filtered = await PenPal.Jobs.GetFiltered(filterMode);

// ❌ WRONG - Common API naming mistakes
await PenPal.JobsTracker.insertJob(); // Use PenPal.Jobs.Create() instead
await PenPal.JobsTracker.updateJob(); // Use PenPal.Jobs.Update() instead
await PenPal.JobsTracker.updateJobStage(); // Use PenPal.Jobs.UpdateStage() instead
const jobs = []; // Local job arrays - use centralized API instead
const job_id = "manual-id"; // Manual ID generation - let API handle IDs
```

### Job Structure

**Basic Job Fields:**
```javascript
const jobData = {
  name: "Descriptive Job Name",
  plugin: "YourPluginName", // Auto-populated if not provided
  statusText: "Initial status message",
  progress: 0, // 0-100 percentage
  status: "running", // running, done, failed, cancelled
  // Optional fields:
  stages: [/* array of stage objects */],
};
```

**Job with Stages:**
```javascript
const jobWithStages = {
  name: "Multi-Stage Job",
  plugin: "YourPluginName",
  statusText: "Starting multi-stage process",
  progress: 0,
  stages: [
    {
      name: "Stage 1: Preparation",
      statusText: "Preparing environment",
      progress: 0,
      status: "pending"
    },
    {
      name: "Stage 2: Execution", 
      statusText: "Running main process",
      progress: 0,
      status: "pending"
    },
    {
      name: "Stage 3: Cleanup",
      statusText: "Cleaning up resources",
      progress: 0,
      status: "pending"
    }
  ]
};
```

### ⚠️ CRITICAL: Jobs API Naming Convention

**✅ ALWAYS use `PenPal.Jobs`, NEVER `PenPal.JobsTracker`**

```javascript
// ✅ CORRECT - Use PenPal.Jobs namespace
await PenPal.Jobs.Create(jobData);
await PenPal.Jobs.Update(job_id, updates);
await PenPal.Jobs.UpdateStage(job_id, stage_index, updates);

// ❌ WRONG - Don't use PenPal.JobsTracker
await PenPal.JobsTracker.insertJob(jobData);     // INCORRECT API NAME
await PenPal.JobsTracker.updateJob(job_id, data); // INCORRECT API NAME
await PenPal.JobsTracker.updateJobStage(job_id, stage, data); // INCORRECT API NAME

// ❌ WRONG - Don't try to access JobsTracker directly
PenPal.JobsTracker = PenPal.Plugins.JobsTracker.API; // NOT NEEDED
```

The JobsTracker plugin exposes its API through the `PenPal.Jobs` namespace automatically. Do not attempt to manually set up API access in your plugin's `loadPlugin()` function.

### Jobs API Methods

**Create Job:**
```javascript
// Simple job without stages
const job = await PenPal.Jobs.Create({
  name: "Network Scan",
  statusText: "Starting network scan",
  progress: 0
});

// Job with stages
const job = await PenPal.Jobs.Create(jobWithStages);
```

**Update Job:**
```javascript
// Update job progress and status
await PenPal.Jobs.Update(job.id, {
  progress: 50,
  statusText: "Halfway complete"
});

// Mark job as complete
await PenPal.Jobs.Update(job.id, {
  progress: 100,
  status: "done",
  statusText: "Scan complete"
});
```

**Update Job Progress (Convenience Method):**
```javascript
// Quick progress update
await PenPal.Jobs.UpdateProgress(job.id, 75);
```

**Update Job Stage:**
```javascript
// Update specific stage by index (0-based)
await PenPal.Jobs.UpdateStage(job.id, 0, {
  progress: 100,
  status: "done",
  statusText: "Preparation complete"
});

// Start next stage
await PenPal.Jobs.UpdateStage(job.id, 1, {
  progress: 0,
  status: "running",
  statusText: "Beginning execution"
});
```

**Retrieve Jobs:**
```javascript
// Get specific job
const job = await PenPal.Jobs.Get(job_id);

// Get all jobs
const allJobs = await PenPal.Jobs.GetAll();

// Get filtered jobs
const activeJobs = await PenPal.Jobs.GetFiltered("active");
const recentJobs = await PenPal.Jobs.GetFiltered("recent");
```

### Job Management Best Practices

**Job Lifecycle Management:**
```javascript
// 1. Create job
const job = await PenPal.Jobs.Create({
  name: "Host Discovery Scan",
  statusText: "Initializing scan parameters",
  progress: 0
});

try {
  // 2. Update progress during execution
  await PenPal.Jobs.UpdateProgress(job.id, 25);
  await performScanStep1();
  
  await PenPal.Jobs.Update(job.id, {
    progress: 50,
    statusText: "Scanning network ranges"
  });
  await performScanStep2();
  
  // 3. Complete successfully
  await PenPal.Jobs.Update(job.id, {
    progress: 100,
    status: PenPal.Jobs.Status.DONE,
    statusText: "Scan completed successfully"
  });
  
} catch (error) {
  // 4. Handle failures
  await PenPal.Jobs.Update(job.id, {
    status: PenPal.Jobs.Status.FAILED,
    statusText: `Scan failed: ${error.message}`
  });
}
```

**Multi-Stage Job Management:**
```javascript
const job = await PenPal.Jobs.Create({
  name: "Comprehensive Security Scan",
  stages: [
    { name: "Port Scan", statusText: "Scanning ports", progress: 0, status: PenPal.Jobs.Status.PENDING },
    { name: "Service Detection", statusText: "Detecting services", progress: 0, status: PenPal.Jobs.Status.PENDING },
    { name: "Vulnerability Assessment", statusText: "Checking vulnerabilities", progress: 0, status: PenPal.Jobs.Status.PENDING }
  ]
});

// Execute stage 1
await PenPal.Jobs.UpdateStage(job.id, 0, { status: PenPal.Jobs.Status.RUNNING });
await performPortScan();
await PenPal.Jobs.UpdateStage(job.id, 0, { 
  progress: 100, 
  status: PenPal.Jobs.Status.DONE,
  statusText: "Port scan complete"
});

// Execute stage 2
await PenPal.Jobs.UpdateStage(job.id, 1, { status: PenPal.Jobs.Status.RUNNING });
await performServiceDetection();
await PenPal.Jobs.UpdateStage(job.id, 1, { 
  progress: 100, 
  status: PenPal.Jobs.Status.DONE,
  statusText: "Service detection complete"
});

// Update overall job progress
await PenPal.Jobs.UpdateProgress(job.id, 100);
```

### Integration with Security Tools

**Example: Nmap Integration**
```javascript
// Replace local job management with Jobs API
export const start_detailed_hosts_scan = async (hosts) => {
  const job = await PenPal.Jobs.Create({
    name: `Detailed Host Scan for ${hosts.length} hosts`,
    statusText: "Preparing detailed scan",
    progress: 0,
    stages: [
      { name: "Port Scan", statusText: "Scanning ports", progress: 0, status: PenPal.Jobs.Status.PENDING },
      { name: "Service Detection", statusText: "Detecting services", progress: 0, status: PenPal.Jobs.Status.PENDING },
      { name: "OS Detection", statusText: "Identifying operating systems", progress: 0, status: PenPal.Jobs.Status.PENDING }
    ]
  });

  // Pass job_id to scan function instead of job_stages
  performScan(hosts, job.id);
  return job.id;
};
```

### Job Status and Filtering

**✅ CRITICAL: Standardized Job Status Constants**
Always use the predefined status constants to ensure consistency:

```javascript
// ✅ CORRECT Status constants
PenPal.Jobs.Status.PENDING    // "pending" - Job is queued/waiting
PenPal.Jobs.Status.RUNNING    // "running" - Job is actively executing  
PenPal.Jobs.Status.DONE       // "done" - Job completed successfully
PenPal.Jobs.Status.FAILED     // "failed" - Job failed with error
PenPal.Jobs.Status.CANCELLED  // "cancelled" - Job was cancelled

// ✅ CORRECT Check if status is completed
const isCompleted = PenPal.Jobs.CompletedStatuses.includes(job.status);

// ❌ WRONG - Don't use hardcoded status strings
status: "completed" // Invalid status - use PenPal.Jobs.Status.DONE
status: "finished"  // Invalid status - use PenPal.Jobs.Status.DONE
status: "running"   // Use PenPal.Jobs.Status.RUNNING instead
```

**Job Status Values:**
- `PenPal.Jobs.Status.PENDING` - Job is queued/waiting to start
- `PenPal.Jobs.Status.RUNNING` - Job is currently executing
- `PenPal.Jobs.Status.DONE` - Job completed successfully
- `PenPal.Jobs.Status.FAILED` - Job encountered an error
- `PenPal.Jobs.Status.CANCELLED` - Job was manually cancelled

**Filter Modes:**
- `"active"` - Shows running jobs and recent completed jobs (default UI view)
- `"recent"` - Shows jobs from the last 24 hours
- `"all"` - Shows all jobs with pagination

### Automatic Job Cleanup

The JobsTracker automatically cleans up stale jobs:
- Jobs not updated for 5+ minutes are marked as "cancelled"
- Cleanup runs every 5 minutes automatically
- Prevents accumulation of orphaned jobs from crashed processes

### UI Integration

The JobsTracker provides a comprehensive UI at `/jobs` with:
- **Real-time job monitoring** with 500ms polling
- **Progress visualization** with color-coded progress bars
- **Stage-by-stage tracking** for complex jobs
- **Filtering and pagination** for job history
- **Runtime and completion time tracking**
- **Automatic cleanup** of stale jobs

### Migration from Local Job Management

**Before (Local Job Management):**
```javascript
// ❌ Old pattern - local job arrays
const jobs = [];
const job_id = generateId();
jobs.push({ id: job_id, name: "Scan", progress: 0 });
```

**After (Jobs API):**
```javascript
// ✅ New pattern - centralized Jobs API
const job = await PenPal.Jobs.Create({
  name: "Scan",
  progress: 0
});
```

The Jobs API provides better reliability, persistence, monitoring, and user experience compared to local job management.

## GraphQL Integration
Plugins extend the GraphQL schema with:
- Custom types and mutations
- Resolvers and data loaders  
- Schema stitching via plugin loading system
- **Real-time subscriptions** via WebSocket

### GraphQL Subscriptions & Real-time Updates

**✅ CRITICAL: WebSocket Subscription Support**
PenPal supports real-time GraphQL subscriptions using WebSocket transport while maintaining full Apollo Client compatibility.

#### Server-Side Subscription Setup

**PubSub System:**
```javascript
// PubSub is automatically available in all plugins
export const updateItem = async (item_id, updates) => {
  const result = await PenPal.DataStore.updateOne("PluginName", "Items", { id: item_id }, updates);
  
  // Publish real-time update
  if (PenPal.PubSub) {
    const updatedItem = await getItem(item_id);
    PenPal.PubSub.publish('ITEM_UPDATED', { itemUpdated: updatedItem });
  }
  
  return result;
};
```

**Subscription Schema:**
```graphql
# plugin/graphql/schema/subscriptions.graphql
extend type Subscription {
  itemUpdated: Item
  itemCreated: Item
  itemDeleted: ID
}
```

**Subscription Resolvers:**
```javascript
// plugin/graphql/resolvers/subscriptions.js
export default {
  async itemUpdated(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_UPDATED']);
  },
  
  async itemCreated(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_CREATED']);
  },
  
  async itemDeleted(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_DELETED']);
  },
};
```

**✅ CRITICAL: Correct Subscription Resolver Pattern**

GraphQL subscription resolvers MUST use the **object pattern with `subscribe` method**, not direct function patterns:

```javascript
// ✅ CORRECT: Object resolvers with subscribe method
export default {
  jobUpdated: {
    subscribe: (parent, args, context) => {
      if (!context?.pubsub) {
        throw new Error("PubSub not available in subscription context");
      }
      return context.pubsub.asyncIterator(["JOB_UPDATED"]);
    }
  },
  
  jobCreated: {
    subscribe: (parent, args, context) => {
      return context.pubsub.asyncIterator(["JOB_CREATED"]);
    }
  },
  
  activeJobsChanged: {
    subscribe: (parent, args, context) => {
      return context.pubsub.asyncIterator(["ACTIVE_JOBS_CHANGED"]);
    }
  }
};

// ❌ WRONG: Direct function resolvers (will fail with "must return Async Iterable" error)
export default {
  async jobUpdated(parent, args, context) {
    return context.pubsub.asyncIterator(["JOB_UPDATED"]); // This pattern doesn't work!
  }
};
```

**Why This Matters:**
- GraphQL requires subscription resolvers to return async iterables
- The function pattern fails with "Subscription field must return Async Iterable. Received: undefined."
- The object pattern with `subscribe` method is the GraphQL specification standard
- Using the wrong pattern causes WebSocket disconnections with 4500 error codes

**Debugging Subscription Issues:**
If subscriptions fail with "Internal error occurred during message handling", check:
1. **Resolver Pattern**: Use object resolvers with `subscribe` method
2. **PubSub Availability**: Ensure `context.pubsub` is available in WebSocket context
3. **AsyncIterator Creation**: Verify `pubsub.asyncIterator()` succeeds
4. **Schema Registration**: Confirm subscription resolvers are properly exported

**Resolver Registration:**
```javascript
// plugin/graphql/resolvers.js
export default [
  {
    Query: { ...resolvers.queries },
    Mutation: { ...resolvers.mutations },
    Subscription: { ...resolvers.subscriptions }, // Add subscriptions
  },
  ...resolvers.default_resolvers,
  ...resolvers.scalars,
];
```

#### Client-Side Subscription Usage

**Subscription Query:**
```javascript
// plugin/client/queries/item-subscription.js
import { gql } from "@apollo/client";

const ITEM_UPDATED_SUBSCRIPTION = gql`
  subscription ItemUpdated {
    itemUpdated {
      id
      name
      status
      updated_at
    }
  }
`;

export default ITEM_UPDATED_SUBSCRIPTION;
```

**React Component with Subscriptions:**
```javascript
import React, { useState, useEffect } from "react";
import { useQuery, useSubscription } from "@apollo/client";

const ItemComponent = () => {
  const [items, setItems] = useState([]);

  // Initial query
  const { data, loading } = useQuery(GET_ITEMS, {
    onCompleted: (data) => setItems(data?.getItems || []),
  });

  // Real-time subscription
  const { data: subscriptionData } = useSubscription(ITEM_UPDATED_SUBSCRIPTION, {
    onData: ({ data }) => {
      if (data?.data?.itemUpdated) {
        const updatedItem = data.data.itemUpdated;
        setItems(prev => prev.map(item => 
          item.id === updatedItem.id ? updatedItem : item
        ));
      }
    },
    onError: (error) => {
      console.warn("Subscription error, falling back to polling:", error);
    },
  });

  // Fallback polling if subscription fails
  useEffect(() => {
    if (subscriptionData?.error) {
      const interval = setInterval(() => {
        // Refetch data as fallback
      }, 5000);
      return () => clearInterval(interval);
    }
  }, [subscriptionData]);

  return (
    <div>
      {items.map(item => (
        <div key={item.id}>{item.name} - {item.status}</div>
      ))}
    </div>
  );
};
```

#### WebSocket Configuration

**Server WebSocket Setup:**
The GraphQL server automatically configures WebSocket support:
- **WebSocket endpoint**: `ws://localhost:3001/graphql`
- **HTTP endpoint**: `http://localhost:3001/graphql`
- **Split transport**: Subscriptions via WebSocket, queries/mutations via HTTP

**Client Apollo Configuration:**
Apollo Client is pre-configured with split link transport:
```javascript
// Automatic split: subscriptions use WebSocket, queries/mutations use HTTP
const apollo_client = new ApolloClient({
  cache,
  link: splitLink, // Automatically routes based on operation type
});
```

#### Common Subscription Patterns

**Real-time Job Updates (JobsTracker Example):**
```javascript
// Server: Publish job updates
export const updateJob = async (job_id, updates) => {
  const result = await PenPal.DataStore.updateOne("JobsTracker", "Jobs", { id: job_id }, updates);
  
  // Real-time notification
  if (PenPal.PubSub) {
    const updatedJob = await getJob(job_id);
    PenPal.PubSub.publish('JOB_UPDATED', { jobUpdated: updatedJob });
    
    // Aggregate updates
    const activeJobs = await getActiveJobs();
    PenPal.PubSub.publish('ACTIVE_JOBS_CHANGED', { activeJobsChanged: activeJobs });
  }
  
  return result;
};

// Client: Subscribe to job changes
const { data } = useSubscription(ACTIVE_JOBS_SUBSCRIPTION, {
  onData: ({ data }) => {
    if (data?.data?.activeJobsChanged) {
      setActiveJobs(data.data.activeJobsChanged);
    }
  },
});
```

**Service Discovery Updates:**
```javascript
// Server: Publish service discoveries
PenPal.PubSub.publish('NEW_SERVICES_DISCOVERED', { 
  newServicesDiscovered: { project_id, services } 
});

// Client: Real-time service updates
const { data } = useSubscription(SERVICE_DISCOVERY_SUBSCRIPTION, {
  variables: { projectId },
  onData: ({ data }) => {
    if (data?.data?.newServicesDiscovered) {
      // Update UI immediately
      addNewServices(data.data.newServicesDiscovered.services);
    }
  },
});
```

#### Subscription Best Practices

**Event Naming Conventions:**
- Use UPPER_SNAKE_CASE for event names
- Include context: `JOB_UPDATED`, `SERVICE_DISCOVERED`, `HOST_SCAN_COMPLETE`
- Group related events: `ACTIVE_JOBS_CHANGED` aggregates multiple job events

**Error Handling:**
- Always implement subscription error handlers
- Provide fallback to polling for reliability
- Log subscription errors for debugging

**Performance Considerations:**
- Use aggregated subscriptions (e.g., `activeJobsChanged`) instead of individual item subscriptions
- Implement proper subscription cleanup in React components
- Consider subscription filtering on server-side for large datasets

**Security & Context:**
- Subscriptions inherit the same authentication context as queries/mutations
- PubSub events are server-wide - filter sensitive data appropriately
- Consider user-specific subscriptions for multi-tenant scenarios

#### WebSocket vs Polling

**Use Subscriptions For:**
- Real-time status updates (jobs, scans, discoveries)
- Live dashboards and monitoring
- Collaborative features
- Critical alerts and notifications

**Use Polling For:**
- One-time data fetching
- Backup/fallback scenarios
- Non-critical periodic updates
- Client-side state management

## DataStore API Usage

**✅ CRITICAL: DataStore API Signature**
All DataStore operations require **plugin name** and **store name** as first two parameters:

```javascript
// ✅ CORRECT DataStore API usage
await PenPal.DataStore.fetch("PluginName", "StoreName", query);
await PenPal.DataStore.fetchOne("PluginName", "StoreName", query);
await PenPal.DataStore.insertMany("PluginName", "StoreName", [data]);
await PenPal.DataStore.updateOne("PluginName", "StoreName", query, updates);
await PenPal.DataStore.delete("PluginName", "StoreName", query);

// ❌ WRONG - These methods don't exist
await PenPal.DataStore.getAll("StoreName");
await PenPal.DataStore.get("StoreName", id);
await PenPal.DataStore.insert("StoreName", data);
```

**DataStore Configuration in plugin.js:**
```javascript
const settings = {
  datastores: [
    {
      name: "YourStoreName", // This becomes the "StoreName" parameter
    },
  ],
};
```

**Common DataStore Patterns:**
- **Single Record**: `fetchOne("Plugin", "Store", { id: "some-id" })`
- **Multiple Records**: `fetch("Plugin", "Store", { status: "active" })`
- **Query by Array**: `fetch("Plugin", "Store", { id: { $in: [id1, id2] } })`
- **Insert Single**: `insertMany("Plugin", "Store", [singleRecord])[0]`
- **Update**: `updateOne("Plugin", "Store", { id: "some-id" }, updateData)`
- **Delete**: `delete("Plugin", "Store", { id: "some-id" })`

## GraphQL Schema Conflicts

**✅ Avoiding Type Conflicts:**
- Check existing GraphQL types before creating new ones
- Use unique type names prefixed with plugin name if needed
- Remove conflicting types from Base plugin when migrating functionality

**Common Conflict Scenarios:**
```graphql
# ❌ This will cause conflicts if Job type already exists elsewhere
type Job {
  id: ID!
  name: String!
}

# ✅ Use plugin-specific prefixes if conflicts arise
type JobsTrackerJob {
  id: ID!
  name: String!
}
```

**Scalar Type Usage:**
- Use existing scalars like `JSON` instead of `JSONObject`
- Check [PenPal/app/src/server/graphql/schema/scalars.graphql](mdc:PenPal/app/src/server/graphql/schema/scalars.graphql) for available types
- Consistent scalar usage prevents "Unknown type" errors

## Plugin Development Best Practices

**API Layer Structure:**
```javascript
// api/index.js - Clean separation of concerns
export const getItems = async (item_id) => {
  return await PenPal.DataStore.fetchOne("PluginName", "Items", { id: item_id });
};

export const insertItem = async (item_data) => {
  const item_with_timestamps = {
    ...item_data,
    id: item_data.id || PenPal.Utils.UUID(),
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
  };
  const result = await PenPal.DataStore.insertMany("PluginName", "Items", [item_with_timestamps]);
  return result[0];
};
```

**Plugin Registration Pattern:**
```javascript
// plugin.js - Register APIs on PenPal object
PenPal.YourAPI = {
  Get: API.getItem,
  Insert: API.insertItem,
  Update: API.updateItem,
  // Helper functions
  Create: async (itemData) => { /* convenience wrapper */ },
};
```

**Dependency Management:**
- Always specify plugin dependencies in manifest.json
- Use `"load": false` temporarily during development to prevent loading
- DataStore-dependent plugins must list `"DataStore@0.1.0"` in dependencies
- Docker-dependent plugins must list `"Docker@0.1.0"` in dependencies

**Migration Considerations:**
- When moving functionality from one plugin to another, update both GraphQL schemas
- Remove old resolvers and types to prevent conflicts
- Update client-side GraphQL queries to use new endpoints
- Consider backward compatibility for existing data

**Testing DataStore Integration:**
- Test with empty database first
- Verify all CRUD operations work correctly
- Check query syntax with MongoDB-style operators (`$in`, `$lt`, etc.)
- Ensure proper error handling for missing records

**Client-Server Plugin Coordination:**
- Client plugins should mirror server plugin structure
- Use consistent naming between client queries and server resolvers
- Implement proper loading states and error handling in React components
- Consider real-time updates with polling or subscriptions

## Lessons Learned from Plugin Development

### MQTT-Triggered Plugin Pattern

**✅ Service Discovery Chain:**
The HttpX plugin demonstrates the standard pattern for chained service discovery:

```javascript
// ✅ CORRECT Pattern for service-triggered plugins
const HttpXPlugin = {
  async loadPlugin() {
    const MQTT = await PenPal.MQTT.NewClient();
    
    // Subscribe to upstream service discovery events
    await MQTT.Subscribe(
      PenPal.API.MQTT.Topics.New.Services,
      async ({ project, service_ids }) => {
        // Filter for relevant services
        const services = await PenPal.API.Services.GetMany(service_ids);
        const candidates = services.filter(service => 
          service.ip_protocol === "TCP" && 
          service.status === "open" &&
          service.port
        );
        
        if (candidates.length > 0) {
          await performToolSpecificScan(candidates);
        }
      }
    );
  },
};
```

### Service Enrichment Pattern

**✅ Standardized Enrichment Workflow:**
```javascript
// ✅ CORRECT Service enrichment pattern
export const parseAndUpsertResults = async (project_id, services_data, output_data) => {
  const results = parseToolOutput(output_data);
  const service_updates = [];
  
  for (const result of results) {
    // Match results to original services
    const matching_service = services_data.find(service => 
      service.host_ip === result.host && service.port === result.port
    );
    
    if (matching_service) {
      // Create plugin-specific enrichment
      const enrichment = {
        plugin_name: "YourPlugin",
        // Tool-specific fields
        ...result
      };
      
      // Append to existing enrichments
      const updated_enrichments = [
        ...(matching_service.enrichments || []),
        enrichment
      ];
      
      service_updates.push({
        id: matching_service.id,
        enrichments: updated_enrichments
      });
    }
  }
  
  // Bulk update services
  if (service_updates.length > 0) {
    await PenPal.API.Services.UpsertMany(service_updates);
  }
};
```

### Host IP Resolution Pattern

**✅ Host Data Enrichment:**
```javascript
// ✅ CORRECT Pattern for resolving host IPs
const network_services = services.filter(/* filtering logic */);

// Get host information for services
const hosts_map = {};
for (const service of network_services) {
  if (service.host && !hosts_map[service.host]) {
    const host_data = await PenPal.API.Hosts.GetOne(service.host);
    hosts_map[service.host] = host_data;
    service.host_ip = host_data?.ip_address;
  } else if (hosts_map[service.host]) {
    service.host_ip = hosts_map[service.host].ip_address;
  }
}
```

### File I/O with Containers

**✅ Volume Mount File Exchange:**
```javascript
// ✅ CORRECT Pattern for container file I/O
export const performContainerizedScan = async ({ services, project_id }) => {
  const outdir_base = "/penpal-plugin-share";
  const outdir = path.join(outdir_base, "toolname", project_id);
  PenPal.Utils.MkdirP(outdir);
  
  // Create input file on host
  const targets_file = path.join(outdir, `targets-${PenPal.Utils.Epoch()}.txt`);
  const targets = services.map(s => `${s.host_ip}:${s.port}`);
  fs.writeFileSync(targets_file, targets.join('\n'));
  
  // Create output file path
  const output_file = path.join(outdir, `results-${PenPal.Utils.Epoch()}.json`);
  
  // Convert to container paths (volume mount)
  const container_targets = targets_file.replace(outdir_base, "/penpal-plugin-share");
  const container_output = output_file.replace(outdir_base, "/penpal-plugin-share");
  
  // Run tool in container
  const result = await PenPal.Docker.Run({
    image: settings.docker.name,
    cmd: `tool-command -i ${container_targets} -o ${container_output}`,
    daemonize: true,
    volume: { name: "penpal_penpal-plugin-share", path: "/penpal-plugin-share" },
    network: "penpal_penpal"
  });
  
  // Wait for completion and read results
  await PenPal.Docker.Wait(result.stdout.trim());
  const results = fs.readFileSync(output_file, 'utf8');
  return parseResults(results);
};
```

### Plugin Manifest Best Practices

**✅ Development-Ready Manifest:**
```json
{
  "name": "YourPlugin",
  "version": "0.1.0",
  "dependsOn": ["CoreAPI@0.1.0", "Docker@0.1.0", "JobsTracker@0.1.0"],
  "load": false  // Disable during development
}
```

### GraphQL Schema Organization

**✅ Plugin-Specific Schema Structure:**
```
server/graphql/
├── index.js                    // Schema loader
├── resolvers.js               // Resolver structure
├── schema/
│   ├── index.js               // loadGraphQLFiles implementation
│   └── enrichment.schema.graphql  // Plugin-specific types (MUST contain valid GraphQL)
└── resolvers/
    ├── index.js               // Resolver exports
    └── enrichment.default.js  // Plugin resolvers
```

**⚠️ IMPORTANT: GraphQL File Requirements**
- All `.graphql` files MUST contain valid GraphQL definitions (types, queries, mutations, etc.)
- Files with only comments will cause "Unexpected <EOF>" syntax errors
- Remove empty schema files or add minimal valid definitions
- Use specific filenames like `plugin-name-enrichment.schema.graphql` for clarity

**✅ CRITICAL: Correct GraphQL Loading Pattern**
Plugins must follow the established pattern for loading GraphQL files:

```javascript
// ✅ CORRECT: graphql/index.js
export { default as loadGraphQLFiles } from "./schema/index.js";
export { default as resolvers } from "./resolvers.js";

// ❌ WRONG - Don't import from penpal/core
import { loadGraphQLFiles } from "#penpal/core"; // This function doesn't exist
```

**GraphQL Schema Loading Implementation:**
```javascript
// ✅ CORRECT: graphql/schema/index.js
import PenPal from "#penpal/core";
import { dirname, join } from "path";
import { fileURLToPath } from "url";
const __dirname = dirname(fileURLToPath(import.meta.url));
const cur_dir = join(__dirname, ".");

const loadGraphQLFiles = async () => {
  return PenPal.Utils.LoadGraphQLDirectories(cur_dir);
};

export default loadGraphQLFiles;
```

**Resolver Structure:**
```javascript
// ✅ CORRECT: graphql/resolvers.js
import resolvers from "./resolvers/index.js";

export default [
  {
    Query: { ...resolvers.queries },
    Mutation: { ...resolvers.mutations },
    Subscription: { ...resolvers.subscriptions }, // Add subscriptions
  },
  ...resolvers.default_resolvers,
  ...resolvers.scalars,
];
```

**✅ CRITICAL: Plugin Registration Pattern**
Every plugin MUST have an `index.js` file that registers the plugin with PenPal:

```javascript
// ✅ CORRECT: server/index.js
// Overall PenPal coordinating server code
import PenPal from "#penpal/core";

// Plugin-specific info
import Plugin from "./plugin.js";
import Manifest from "./manifest.json" with { type: "json" };

// Register the plugin
PenPal.registerPlugin(Manifest, Plugin);

// ❌ WRONG - Don't export or return anything
export default Plugin; // Remove this line
```

**Key Requirements:**
- Import `PenPal` from `#penpal/core`
- Import `Plugin` from `./plugin.js`
- Import `Manifest` from `./manifest.json` with JSON assertion
- Call `PenPal.registerPlugin(Manifest, Plugin)`
- No exports needed - registration is a side effect

**Plugin Integration:**
```javascript
// ✅ CORRECT: plugin.js
import { loadGraphQLFiles, resolvers } from "./graphql/index.js";

const YourPlugin = {
  loadPlugin() {
    return {
      graphql: {
        types: loadGraphQLFiles,
        resolvers,
      },
    };
  },
};

export default YourPlugin;
```

## Dependency Cycle Resolution

**✅ DataStore Adapter Readiness System**
When plugins depend on DataStore (like Jobs API) but DataStore depends on Docker for databases:

```javascript
// ✅ CORRECT DataStore readiness checking
if (PenPal.DataStore && PenPal.DataStore.AdaptersReady()) {
  // DataStore is ready, use directly
  const job = await PenPal.Jobs.Create(jobData);
} else {
  // DataStore not ready, defer the operation
  await DeferJobCreateOrUpdate(PenPal.Jobs.Create, jobData);
}

// ✅ CORRECT Deferred job system implementation
const DeferJobCreateOrUpdate = (jobsFunction, ...args) => {
  if (PenPal.DataStore && PenPal.DataStore.AdaptersReady()) {
    return jobsFunction(...args);
  } else {
    return new Promise((resolve, reject) => {
      DeferredJobs.queue.push({ function: jobsFunction, args, resolve, reject });
      if (!DeferredJobs.timer) startDeferredJobsTimer();
    });
  }
};

// ❌ WRONG - Circular dependency issues
const job = await PenPal.Jobs.Create(jobData); // May fail if DataStore isn't ready
```

**DataStore Adapter Implementation:**
```javascript
// ✅ CORRECT Adapter readiness implementation
MongoAdapter.isReady = async () => {
  try {
    if (!MongoAdapter.client) return false;
    await MongoAdapter.client.db("admin").command({ ping: 1 });
    return true;
  } catch (error) {
    return false;
  }
};

// ✅ CORRECT Adapter registration with readiness notification
await MongoAdapter.connect();
PenPal.DataStore.RegisterAdapter("MongoAdapter", MongoAdapter);
PenPal.DataStore.SetAdaptersReady(true); // Mark as ready
```

## Common Pitfalls to Avoid

1. **❌ Using non-existent DataStore methods** - Always check CoreAPI usage patterns
2. **❌ Missing plugin/store parameters** - DataStore requires both plugin name and store name
3. **❌ GraphQL type conflicts** - Check for existing types before creating new ones
4. **❌ Incorrect scalar references** - Use existing scalars like `JSON` instead of `JSONObject`
5. **❌ Forgetting timestamps** - Always add `created_at` and `updated_at` fields
6. **❌ Not handling arrays properly** - Use `insertMany()` even for single records
7. **❌ Missing error handling** - Always handle cases where records don't exist
8. **❌ Inconsistent ID generation** - Use `PenPal.Utils.UUID()` for consistent ID format
9. **❌ Hardcoded container paths** - Use volume mount path replacement patterns
10. **❌ Missing Docker dependencies** - Include Docker@0.1.0 for containerized tools
11. **❌ Wrong Jobs API naming** - Use `PenPal.Jobs.Create()` NOT `PenPal.JobsTracker.insertJob()`
12. **❌ Improper job status handling** - Use standardized status constants
13. **❌ Local job management** - Use centralized Jobs API instead of local arrays
14. **❌ Missing host IP resolution** - Enrich services with host data before processing
15. **❌ Inefficient service filtering** - Filter services early to avoid unnecessary processing
16. **❌ Missing volume validation** - Ensure Docker volumes exist and are properly configured
17. **❌ Wrong GraphQL loading pattern** - Don't import `loadGraphQLFiles` from `#penpal/core`
18. **❌ Missing plugin registration** - Every plugin needs `PenPal.registerPlugin()` in `index.js`
19. **❌ Empty GraphQL schema files** - Remove files with only comments, GraphQL requires actual definitions
20. **❌ Circular dependency issues** - Use deferred job system when DataStore adapters aren't ready
21. **❌ Hardcoded status strings** - Use shared constants instead of magic strings
22. **❌ Complex client plugin.js** - Keep client plugins simple, following CoreAPI pattern
23. **❌ Wrong subscription resolver pattern** - Use object resolvers with `subscribe` method, not direct function resolvers
24. **❌ Missing pubsub context validation** - Always check `context?.pubsub` exists before calling `asyncIterator()`
25. **❌ Not checking Docker image readiness** - Always check `PenPal.Docker.IsImageReady()` before running containers since builds are now background

## Shared Constants and Status Management

**✅ CRITICAL: Centralized Constants Pattern**
When developing plugins that share status values, enums, or other constants between client and server, always create a shared constants file in the `common/` directory.

### Creating Shared Constants

**Directory Structure:**
```
Plugins/YourPlugin/
├── client/
│   ├── plugin.js           // Simple pattern - no constants export
│   └── components/
├── server/
│   ├── plugin.js           // Imports and uses constants
│   └── api/
├── common/
│   └── your-constants.js   // Shared constants file
```

**Constants File Pattern:**
```javascript
// ✅ CORRECT: Plugins/YourPlugin/common/your-constants.js
export const YourStatus = {
  PENDING: "pending",
  RUNNING: "running",
  DONE: "done",
  FAILED: "failed",
};

export const STATUS_COLLECTIONS = {
  COMPLETED: [YourStatus.DONE, YourStatus.FAILED],
  ACTIVE: [YourStatus.PENDING, YourStatus.RUNNING],
};

// Helper functions
export const isStatusCompleted = (status) => {
  return STATUS_COLLECTIONS.COMPLETED.includes(status);
};

export const validateStatus = (status) => {
  const validStatuses = Object.values(YourStatus);
  if (!validStatuses.includes(status)) {
    throw new Error(`Invalid status: ${status}. Valid: ${validStatuses.join(", ")}`);
  }
  return status;
};
```

### Server Plugin Integration

**✅ CORRECT: Server plugin imports and exposes constants**
```javascript
// server/plugin.js
import { YourStatus, STATUS_COLLECTIONS, validateStatus } from "../common/your-constants.js";

const YourPlugin = {
  async loadPlugin() {
    // Expose constants through PenPal API
    PenPal.YourAPI = {
      Status: YourStatus,
      StatusCollections: STATUS_COLLECTIONS,
      ValidateStatus: validateStatus,
      // ... other API methods
    };

    return { settings };
  },
};
```

**Server API Usage:**
```javascript
// server/api/index.js
import { YourStatus, STATUS_COLLECTIONS } from "../../common/your-constants.js";

export const updateItem = async (item_id, updates) => {
  // Use constants instead of hardcoded strings
  if (updates.status && !Object.values(YourStatus).includes(updates.status)) {
    throw new Error(`Invalid status: ${updates.status}`);
  }

  // Filter by status using constants
  const activeItems = await PenPal.DataStore.fetch("YourPlugin", "Items", {
    status: { $in: STATUS_COLLECTIONS.ACTIVE }
  });

  return result;
};
```

### Client Component Integration

**✅ CORRECT: Direct import in client components**
```javascript
// client/components/your-component.jsx
import { YourStatus, STATUS_COLLECTIONS, isStatusCompleted } from "../../common/your-constants.js";

const YourComponent = ({ items }) => {
  // Use constants for filtering and comparisons
  const activeItems = items.filter(item => 
    STATUS_COLLECTIONS.ACTIVE.includes(item.status)
  );

  const isComplete = isStatusCompleted(item.status);

  return (
    <div>
      {activeItems.map(item => (
        <div key={item.id}>
          {item.name} - {item.status === YourStatus.RUNNING ? "🔄" : "⏸️"}
        </div>
      ))}
    </div>
  );
};
```

### Client Plugin.js Simplicity

**✅ CORRECT: Keep client plugin.js simple**
```javascript
// ❌ WRONG - Don't export constants or complex APIs from client plugin.js
import { registerPlugin } from "@penpal/core";
import routes from "./routes.js";
import { YourStatus, STATUS_COLLECTIONS } from "../common/your-constants.js";

export { YourStatus, STATUS_COLLECTIONS }; // DON'T DO THIS

export default {
  name: "YourPlugin",
  constants: { YourStatus }, // DON'T DO THIS
  // ... complex plugin API
};

// ✅ CORRECT - Follow CoreAPI pattern exactly
import.meta.glob("./**/*.jsx", { eager: true });
import registerRoutes from "./routes.js";

const YourPlugin = {
  loadPlugin() {
    return {
      registerRoutes,
    };
  },
};

export default YourPlugin;
```

### Migration from Hardcoded Strings

**Common Hardcoded String Patterns to Replace:**
```javascript
// ❌ WRONG - Hardcoded status strings
if (job.status === "done") { /* ... */ }
if (job.status !== "cancelled" && job.status !== "failed") { /* ... */ }
const completedJobs = jobs.filter(j => j.status === "done" || j.status === "failed");

// ✅ CORRECT - Using constants
if (job.status === JobStatus.DONE) { /* ... */ }
if (!COMPLETED_STATUSES.includes(job.status)) { /* ... */ }
const completedJobs = jobs.filter(j => COMPLETED_STATUSES.includes(j.status));
```

**Search and Replace Strategy:**
1. **Find all hardcoded strings**: Use `grep -r '"status_value"' Plugins/YourPlugin/`
2. **Create constants file**: Define all status values and collections
3. **Update server code**: Import constants and replace strings
4. **Update client code**: Import constants and replace strings
5. **Test thoroughly**: Ensure all status comparisons work correctly

### Status Synchronization Best Practices

**✅ Consistent Status Values:**
- Use lowercase, hyphenated strings for status values (`"in-progress"`, not `"InProgress"`)
- Keep status names descriptive but concise
- Avoid status values that could be confused (`"complete"` vs `"done"`)

**✅ Status Collections:**
- Group related statuses into collections (`COMPLETED_STATUSES`, `ACTIVE_STATUSES`)
- Use collections for filtering and validation
- Document what each collection represents

**✅ Helper Functions:**
- Provide validation functions (`validateStatus()`)
- Provide state-checking functions (`isStatusCompleted()`, `isStatusActive()`)
- Include transition logic if needed (`canTransitionTo()`)

### Common Status Management Mistakes

1. **❌ Inconsistent casing**: `"Done"` vs `"done"` vs `"DONE"`
2. **❌ Typos in hardcoded strings**: `"cancelled"` vs `"canceled"`
3. **❌ Magic numbers**: Using `status: 1` instead of named constants
4. **❌ Client-server mismatch**: Different status values on client vs server
5. **❌ Missing validation**: Accepting invalid status values
6. **❌ Complex plugin.js**: Exporting constants through client plugin API
7. **❌ Duplicate definitions**: Defining same constants in multiple files

### Testing Status Management

**✅ Test Status Transitions:**
```javascript
// Test all valid status transitions
const validTransitions = [
  [JobStatus.PENDING, JobStatus.RUNNING],
  [JobStatus.RUNNING, JobStatus.DONE],
  [JobStatus.RUNNING, JobStatus.FAILED],
];

validTransitions.forEach(([from, to]) => {
  test(`Can transition from ${from} to ${to}`, () => {
    expect(canTransitionTo(from, to)).toBe(true);
  });
});
```

**✅ Test Status Collections:**
```javascript
// Ensure collections are mutually exclusive and complete
test('Status collections are properly defined', () => {
  const allStatuses = Object.values(JobStatus);
  const completedStatuses = COMPLETED_STATUSES;
  const activeStatuses = ACTIVE_STATUSES;
  
  // No overlap between active and completed
  const overlap = activeStatuses.filter(s => completedStatuses.includes(s));
  expect(overlap).toHaveLength(0);
  
  // All statuses are categorized
  const categorized = [...activeStatuses, ...completedStatuses];
  expect(categorized.sort()).toEqual(allStatuses.sort());
});
```

By following these patterns, plugins will have consistent, maintainable status management that works reliably across client and server components.
