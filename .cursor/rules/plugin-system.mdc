---
description: 
globs: 
alwaysApply: true
---
# PenPal Plugin System Guide

PenPal uses a sophisticated plugin architecture that allows dynamic loading of cybersecurity tools and integrations.

## Plugin Loading System
- **Server Plugin Loader**: [Plugins/plugins-loader-server.js](mdc:Plugins/plugins-loader-server.js)
- **Client Plugin Loader**: [Plugins/plugins-loader-client.js](mdc:Plugins/plugins-loader-client.js)
- **Plugin Development Script**: [penpal-plugin-develop.py](mdc:penpal-plugin-develop.py)

## Core Plugins
- **Base Plugin**: [Plugins/Base/server/manifest.json](mdc:Plugins/Base/server/manifest.json) - Foundation plugin
- **CoreAPI Plugin**: [Plugins/CoreAPI/server/manifest.json](mdc:Plugins/CoreAPI/server/manifest.json) - Data standardization
- **DataStore Plugin**: [Plugins/DataStore/server/plugin.js](mdc:Plugins/DataStore/server/plugin.js) - Data abstraction layer
- **MongoDB Adapter**: [Plugins/DataStoreMongoAdapter/server/plugin.js](mdc:Plugins/DataStoreMongoAdapter/server/plugin.js)
- **JobsTracker Plugin**: [Plugins/JobsTracker/server/plugin.js](mdc:Plugins/JobsTracker/server/plugin.js) - Centralized job management
- **Docker Plugin**: [Plugins/Docker/server/plugin.js](mdc:Plugins/Docker/server/plugin.js) - Container orchestration

## Plugin Structure Requirements
Each plugin must have:
1. **manifest.json** - Plugin metadata, dependencies, and versioning
2. **index.js** - Plugin registration with PenPal core
3. **plugin.js** - Plugin implementation and GraphQL integration
4. **install-dependencies.sh** (optional) - Custom dependency installation
5. **docker-context/** (optional) - Docker build context for containerized tools

## Security Tool Plugins
- **Nmap**: [Plugins/Nmap/server/plugin.js](mdc:Plugins/Nmap/server/plugin.js) - Network scanning
- **Rustscan**: [Plugins/Rustscan/server/plugin.js](mdc:Plugins/Rustscan/server/plugin.js) - Fast port scanning
- **HttpX**: [Plugins/HttpX/server/plugin.js](mdc:Plugins/HttpX/server/plugin.js) - HTTP service discovery

## Service Enrichment System

**✅ CRITICAL: Extensible Service Enrichment Architecture**
PenPal provides a powerful service enrichment system that allows plugins to add rich metadata to discovered services. This creates a comprehensive view of each service with data from multiple security tools.

### Enrichment Architecture

**Core Components:**
- **PluginEnrichment Interface**: GraphQL interface for standardized enrichment data
- **Service Enrichments Array**: Each service can have multiple enrichments from different plugins
- **Plugin-Specific Resolvers**: Custom GraphQL resolvers for each plugin's enrichment type
- **Extensible UI System**: Client-side component registry for custom enrichment displays

### Server-Side Enrichment Implementation

**GraphQL Interface Definition:**
```graphql
# CoreAPI defines the base PluginEnrichment interface
interface PluginEnrichment {
  plugin_name: String!
  data: JSON  # Generic field containing all plugin-specific data
}

# Plugin-specific enrichment types implement the interface
type HttpXPluginEnrichment implements PluginEnrichment {
  plugin_name: String!
  data: JSON
  url: String
  status_code: Int
  content_type: String
  title: String
  tech: [String]
  # ... other HTTP-specific fields
}

type NmapPluginEnrichment implements PluginEnrichment {
  plugin_name: String!
  data: JSON
  service: String
  product: String
  version: String
  fingerprint: String
  # ... other Nmap-specific fields
}
```

**Interface Resolver Registration:**
```javascript
// ✅ CORRECT: Plugin registers its enrichment resolver
import PenPal from "#penpal/core";

const isHttpXPluginEnrichment = (obj) => {
  if (obj.plugin_name === "HttpX") {
    return "HttpXPluginEnrichment";
  }
  return null;
};

// Register with the interface resolver system
PenPal.Utils.RunAfterImport(() => {
  if (!PenPal.API.InterfaceResolvers.PluginEnrichments) {
    PenPal.API.InterfaceResolvers.PluginEnrichments = [];
  }
  PenPal.API.InterfaceResolvers.PluginEnrichments.push(isHttpXPluginEnrichment);
});

export default {
  HttpXPluginEnrichment: {
    url(obj) { return obj.url; },
    status_code(obj) { return obj.status_code; },
    content_type(obj) { return obj.content_type; },
    // ... other field resolvers
    data(obj) {
      // Return all properties except plugin_name as the data object
      const { plugin_name, ...data } = obj;
      return data;
    },
  },
};
```

### Enrichment Creation Pattern

**✅ NEW: CoreAPI Enrichment Management Functions**
The CoreAPI plugin now provides dedicated enrichment management functions that handle service matching and atomic updates automatically. This eliminates the need for plugins to implement complex matching logic.

#### Available Enrichment Functions

**Add Enrichments (Recommended):**
```javascript
// ✅ CORRECT: Use CoreAPI enrichment functions
const enrichment_updates = results.map((result) => ({
  // Service identification - use either approach:
  
  // Option 1: Natural host/port/protocol identification (RECOMMENDED)
  host: result.host,                    // IP address from tool output
  port: result.port,                    // Port number from tool output  
  ip_protocol: "TCP",                   // Protocol (TCP/UDP)
  project_id: project_id,               // Required for multi-project isolation
  
  // Option 2: Direct service ID (for backward compatibility)
  // service_id: "known_service_id",
  
  // Enrichment data
  enrichment: {
    plugin_name: "YourPlugin",
    url: result.url,
    status_code: result.status_code,
    tech: result.tech,
    // ... other tool-specific data
  }
}));

// Add enrichments using CoreAPI function
const result = await PenPal.API.Services.AddEnrichments(enrichment_updates);
console.log(`Successfully added ${result.accepted.length} enrichments, ${result.rejected.length} failed`);
```

**Single Enrichment:**
```javascript
// Add single enrichment
await PenPal.API.Services.AddEnrichment({
  host: "192.168.1.100",
  port: 80,
  ip_protocol: "TCP", 
  project_id: project_id,
  enrichment: {
    plugin_name: "HttpX",
    url: "http://192.168.1.100",
    status_code: 200
  }
});
```

**Update Existing Enrichment:**
```javascript
// Update specific enrichment by plugin name
await PenPal.API.Services.UpdateEnrichment({
  host: "192.168.1.100",
  port: 80,
  ip_protocol: "TCP",
  project_id: project_id,
  plugin_name: "HttpX",
  updates: {
    status_code: 404,
    last_checked: new Date().toISOString()
  }
});
```

**Upsert Enrichment (Add or Update):**
```javascript
// Smart add-or-update logic
await PenPal.API.Services.UpsertEnrichment({
  host: "192.168.1.100", 
  port: 80,
  ip_protocol: "TCP",
  project_id: project_id,
  enrichment: {
    plugin_name: "HttpX",
    url: "http://192.168.1.100",
    status_code: 200,
    title: "Web Server"
  }
});
```

**Remove Enrichment:**
```javascript
// Remove enrichment by plugin name
await PenPal.API.Services.RemoveEnrichment({
  host: "192.168.1.100",
  port: 80, 
  ip_protocol: "TCP",
  project_id: project_id,
  plugin_name: "HttpX"
});
```

#### Service Identification Methods

**Method 1: Host/Port/Protocol (RECOMMENDED)**
Use natural identifiers that plugins already have from tool output:
```javascript
{
  host: "192.168.1.100",        // IP address (string)
  port: 80,                     // Port number (integer)
  ip_protocol: "TCP",           // Protocol: "TCP" or "UDP" 
  project_id: project_id,       // Project ID for isolation
  enrichment: { /* ... */ }
}
```

**Method 2: Service ID (Backward Compatibility)**
Use when you already have the service ID:
```javascript
{
  service_id: "service_123456",  // Known service ID
  enrichment: { /* ... */ }
}
```

#### Enrichment API Benefits

**Data Safety:**
- **Atomic Operations**: Uses MongoDB atomic operators ($push, $set, $pull)
- **Concurrent Safe**: Prevents race conditions during bulk updates
- **Data Preservation**: Existing enrichments from other plugins are preserved

**Plugin Simplicity:**
- **No Manual Matching**: CoreAPI handles service lookup internally
- **Natural Identifiers**: Work with host/port data plugins already have
- **Error Handling**: Comprehensive validation and error reporting

**Architectural Decoupling:**
- **No Service ID Tracking**: Plugins don't need to maintain service ID mappings
- **Consistent Pattern**: Matches existing service upsert behavior
- **Multi-Project Support**: Automatic project isolation

#### Error Handling and Validation

**Response Structure:**
```javascript
const result = await PenPal.API.Services.AddEnrichments(enrichment_updates);

// Result contains:
{
  accepted: [                          // Successfully processed enrichments
    { 
      selector: { host, port, ip_protocol, project_id },
      enrichment: { /* enrichment data */ }
    }
  ],
  rejected: [                          // Failed enrichments with reasons
    {
      selector: { host, port, ip_protocol, project_id },
      enrichment: { /* enrichment data */ },
      error: "Service not found matching criteria"
    }
  ]
}
```

**Common Error Scenarios:**
- **Service Not Found**: No service matches the host/port/protocol in the project
- **Multiple Services Found**: Ambiguous match (should not happen with proper data)
- **Missing Parameters**: Required fields (host, port, ip_protocol, project_id) not provided
- **Invalid Enrichment**: Missing plugin_name or malformed enrichment data

#### Migration from Manual Matching

**Before (Manual Service Matching):**
```javascript
// ❌ OLD: Complex manual matching logic
export const parseAndUpsertResults = async (project_id, services_data, output_data) => {
  const results = parseToolOutput(output_data);
  const service_updates = [];
  
  for (const result of results) {
    // Manual service matching
    const matching_service = services_data.find(service => 
      service.host_ip === result.host && service.port === result.port
    );
    
    if (matching_service) {
      // Manual enrichment array management
      const updated_enrichments = [
        ...(matching_service.enrichments || []),
        { plugin_name: "YourPlugin", ...result }
      ];
      
      service_updates.push({
        id: matching_service.id,
        enrichments: updated_enrichments
      });
    }
  }
  
  // Manual bulk update
  if (service_updates.length > 0) {
    await PenPal.API.Services.UpsertMany(service_updates);
  }
};
```

**After (CoreAPI Enrichment Functions):**
```javascript
// ✅ NEW: Simple enrichment API usage
export const parseAndUpsertResults = async (project_id, services_data, output_data) => {
  const results = parseToolOutput(output_data);
  
  // Convert results to enrichment format
  const enrichment_updates = results.map((result) => ({
    host: result.host,
    port: result.port,
    ip_protocol: "TCP",
    project_id: project_id,
    enrichment: {
      plugin_name: "YourPlugin",
      url: result.url,
      status_code: result.status_code,
      tech: result.tech,
      // ... other tool-specific data
    }
  }));

  // Add enrichments using CoreAPI
  const result = await PenPal.API.Services.AddEnrichments(enrichment_updates);
  console.log(`Successfully added ${result.accepted.length} enrichments`);
  
  if (result.rejected?.length > 0) {
    console.log("Some enrichments were rejected:", 
      result.rejected.map(r => `${r.selector.host}:${r.selector.port} - ${r.error}`)
    );
  }
};
```

**Key Migration Benefits:**
1. **Eliminated ~40 lines** of complex matching logic
2. **Removed dependency** on `services_data` parameter structure  
3. **Improved error handling** with detailed rejection reasons
4. **Enhanced data safety** with atomic database operations
5. **Simplified plugin architecture** with natural identifier usage

#### Legacy Pattern (Deprecated)

**⚠️ DEPRECATED: Manual Service Updates**
The old pattern of manually updating service enrichments is deprecated but still supported:

```javascript
// ❌ DEPRECATED: Manual enrichment management
export const parseAndUpsertResults = async (project_id, services_data, output_data) => {
  const results = parseToolOutput(output_data);
  const service_updates = [];
  
  for (const result of results) {
    const matching_service = services_data.find(service => 
      service.host_ip === result.host && service.port === result.port
    );
    
    if (matching_service) {
      const enrichment = {
        plugin_name: "YourPlugin",
        // Tool-specific fields...
      };
      
      const updated_enrichments = [
        ...(matching_service.enrichments || []),
        enrichment
      ];
      
      service_updates.push({
        id: matching_service.id,
        enrichments: updated_enrichments
      });
    }
  }
  
  if (service_updates.length > 0) {
    await PenPal.API.Services.UpsertMany(service_updates);
  }
};
```

**Migration Recommendations:**
- **New Plugins**: Always use the new enrichment API functions
- **Existing Plugins**: Migrate to new API for better maintainability
- **Legacy Support**: Old pattern continues working but is not recommended

**Key Enrichment Principles:**
- **Plugin Identification**: Always include `plugin_name` field for proper GraphQL resolution
- **Project Isolation**: Always include `project_id` for multi-project support
- **Natural Identifiers**: Use host/port/protocol that tools naturally provide
- **Atomic Operations**: Let CoreAPI handle concurrent access and data integrity
- **Error Tolerance**: Handle rejected enrichments gracefully

### Client-Side Enrichment Display System

**Component Registration Pattern:**
```javascript
// ✅ CORRECT: Plugin registers custom enrichment display component
import PenPal from "@penpal/core";
import HttpXEnrichmentDisplay from "./components/httpx-enrichment-display.jsx";

// Register custom display component
PenPal.API.registerEnrichmentDisplay("HttpX", HttpXEnrichmentDisplay);

console.log("HttpX enrichment display component registered");
```

**Custom Enrichment Display Component:**
```javascript
// ✅ CORRECT: Rich custom display for HttpX enrichments
import React from "react";
import { Box, Typography, Chip, Link } from "@mui/material";
import { OpenInNew, CheckCircle, Error } from "@mui/icons-material";

const HttpXEnrichmentDisplay = ({ enrichment }) => {
  const getStatusColor = (status_code) => {
    if (status_code >= 200 && status_code < 300) return "success";
    if (status_code >= 400) return "error";
    return "default";
  };

  const formatContentLength = (bytes) => {
    if (!bytes) return "Unknown";
    if (bytes < 1024) return `${bytes} B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;
    return `${(bytes / (1024 * 1024)).toFixed(1)} MB`;
  };

  return (
    <Box>
      {/* Clickable URL with external link icon */}
      {enrichment.url && (
        <Box display="flex" alignItems="center" mb={2}>
          <Link href={enrichment.url} target="_blank" rel="noopener">
            {enrichment.url}
          </Link>
          <OpenInNew fontSize="small" sx={{ ml: 1 }} />
        </Box>
      )}

      {/* HTTP Status with color-coded icon */}
      {enrichment.status_code && (
        <Box display="flex" alignItems="center" mb={1}>
          <Typography variant="body2" color="textSecondary" sx={{ mr: 1 }}>
            Status:
          </Typography>
          <Chip
            icon={enrichment.status_code < 400 ? <CheckCircle /> : <Error />}
            label={enrichment.status_code}
            color={getStatusColor(enrichment.status_code)}
            size="small"
          />
        </Box>
      )}

      {/* Technology Stack as chips */}
      {enrichment.tech && enrichment.tech.length > 0 && (
        <Box mb={1}>
          <Typography variant="body2" color="textSecondary" gutterBottom>
            Technology:
          </Typography>
          <Box display="flex" flexWrap="wrap" gap={0.5}>
            {enrichment.tech.map((tech, index) => (
              <Chip key={index} label={tech} size="small" variant="outlined" />
            ))}
          </Box>
        </Box>
      )}

      {/* Additional HTTP metadata */}
      {enrichment.content_length && (
        <Typography variant="body2">
          Size: {formatContentLength(enrichment.content_length)}
        </Typography>
      )}
      
      {enrichment.title && (
        <Typography variant="body2">
          Title: {enrichment.title}
        </Typography>
      )}
    </Box>
  );
};

export default HttpXEnrichmentDisplay;
```

**Default Enrichment Display:**
```javascript
// ✅ Fallback display for plugins without custom components
const DefaultEnrichmentDisplay = ({ enrichment }) => {
  // Show all top-level properties
  const topLevelEntries = Object.entries(enrichment).filter(
    ([key]) => key !== "plugin_name"
  );

  // If there's a data field, also show its contents
  const dataEntries = enrichment.data ? Object.entries(enrichment.data) : [];

  return (
    <Box>
      {topLevelEntries.map(([key, value]) => (
        <Box key={key} display="flex" justifyContent="space-between" mb={1}>
          <Typography variant="body2" color="textSecondary">
            {key.replace(/_/g, " ").replace(/\b\w/g, (l) => l.toUpperCase())}:
          </Typography>
          <Typography variant="body2">
            {typeof value === "object" ? JSON.stringify(value) : String(value)}
          </Typography>
        </Box>
      ))}
      
      {dataEntries.length > 0 && (
        <>
          <Typography variant="caption" color="primary" gutterBottom sx={{ mt: 2, display: "block" }}>
            Data Field Contents:
          </Typography>
          {dataEntries.map(([key, value]) => (
            <Box key={key} display="flex" justifyContent="space-between" mb={1}>
              <Typography variant="body2" color="textSecondary">
                {key.replace(/_/g, " ").replace(/\b\w/g, (l) => l.toUpperCase())}:
              </Typography>
              <Typography variant="body2">
                {Array.isArray(value) ? value.join(", ") : String(value)}
              </Typography>
            </Box>
          ))}
        </>
      )}
    </Box>
  );
};
```

### Services UI Integration

**Services Tab Structure:**
The CoreAPI plugin provides a comprehensive Services UI with three main views:

1. **List View**: Basic service information with enrichment count indicators
2. **Enrichments View**: Detailed plugin enrichment data with custom displays
3. **Graph View**: Network topology visualization (future)

**Services List with Enrichment Indicators:**
```javascript
// Services are displayed with enrichment count badges
const ServiceCard = ({ service }) => (
  <Card>
    <CardHeader
      title={`${service.host?.ip_address}:${service.port}`}
      subheader={`${service.name} (${service.ip_protocol})`}
      action={
        service.enrichments?.length > 0 && (
          <Chip
            label={`${service.enrichments.length} enrichments`}
            size="small"
            color="primary"
          />
        )
      }
    />
    <CardContent>
      {/* Service details */}
      <StatusChip status={service.status} />
      <ProtocolChip protocol={service.ip_protocol} />
    </CardContent>
  </Card>
);
```

**Enrichments View with Plugin Components:**
```javascript
// Each service's enrichments are displayed with plugin-specific components
const ServiceEnrichments = ({ service }) => (
  <Card>
    <CardHeader title={`${service.host?.ip_address}:${service.port}`} />
    <CardContent>
      <Stack spacing={1}>
        {service.enrichments.map((enrichment, index) => {
          // Use registered component or fallback to default
          const DisplayComponent = PenPal.API.EnrichmentDisplayRegistry.get(enrichment.plugin_name) || DefaultEnrichmentDisplay;
          
          return (
            <Accordion key={index}>
              <AccordionSummary expandIcon={<ExpandMoreIcon />}>
                <Typography variant="body1">
                  {enrichment.plugin_name} Enrichment
                  <Chip label={enrichment.plugin_name} size="small" color="primary" sx={{ ml: 1 }} />
                </Typography>
              </AccordionSummary>
              <AccordionDetails>
                <DisplayComponent enrichment={enrichment} />
              </AccordionDetails>
            </Accordion>
          );
        })}
      </Stack>
    </CardContent>
  </Card>
);
```

### MQTT-Triggered Enrichment Pattern

**✅ Event-Driven Service Discovery Chain:**
```javascript
// ✅ CORRECT: Plugin subscribes to service discovery events
const HttpXPlugin = {
  async loadPlugin() {
    const MQTT = await PenPal.MQTT.NewClient();
    
    // Subscribe to new services discovered by other plugins (Nmap, Rustscan, etc.)
    await MQTT.Subscribe(
      PenPal.API.MQTT.Topics.New.Services,
      async ({ project, service_ids }) => {
        console.log("HttpX: New Services:", service_ids);
        
        // Get the service details
        const services = await PenPal.API.Services.GetMany(service_ids);
        
        // Filter for HTTP-capable services
        const network_services = services.filter(service =>
          service.port &&
          service.ip_protocol.toLowerCase() === "tcp" &&
          service.status === "open"
        );
        
        if (network_services.length > 0) {
          // Enrich services with host IP information
          const hosts_map = {};
          for (const service of network_services) {
            if (service.host && !hosts_map[service.host]) {
              const host_data = await PenPal.API.Hosts.Get(service.host);
              hosts_map[service.host] = host_data;
              service.host_ip = host_data?.ip_address;
            } else if (hosts_map[service.host]) {
              service.host_ip = hosts_map[service.host].ip_address;
            }
          }
          
          // Perform HTTP enrichment scan
          await performHttpScan({
            project_id: project,
            services: network_services,
          });
        }
      }
    );
    
    return { graphql: { types, resolvers }, settings };
  },
};
```

### Enrichment Best Practices

**Data Consistency:**
- Always include `plugin_name` field for proper GraphQL interface resolution
- Use consistent field naming across similar plugins (e.g., `status_code` not `statusCode`)
- Provide meaningful default values for optional fields

**Performance Optimization:**
- Use bulk updates with `UpsertMany` instead of individual service updates
- Filter services early to avoid unnecessary processing
- Cache host data when enriching multiple services from the same host

**Error Handling:**
- Handle cases where services don't match tool output
- Validate enrichment data before storing
- Log enrichment statistics for monitoring

**UI Integration:**
- Register custom display components for rich data visualization
- Provide meaningful fallbacks for missing data
- Use consistent Material-UI components and styling

**Security Considerations:**
- Sanitize URLs and external content in enrichment displays
- Validate tool output before storing as enrichments
- Use `target="_blank" rel="noopener"` for external links

### Migration and Compatibility

**Adding Enrichments to Existing Plugins:**
1. Define GraphQL enrichment type implementing `PluginEnrichment`
2. Register interface resolver for your plugin type
3. Update tool parsing to create enrichment objects
4. Use `UpsertMany` with service IDs to append enrichments
5. Create custom display component for rich UI
6. Register display component with `PenPal.API.registerEnrichmentDisplay`

**Backward Compatibility:**
- The `data` field ensures enrichments work even without custom resolvers
- Default display component handles any enrichment structure
- Existing services without enrichments continue to work normally

The Service Enrichment system enables plugins to build comprehensive service intelligence by layering data from multiple security tools, creating a unified view of each discovered service.

## Plugin Development Template
Use [PluginTemplate/](mdc:PluginTemplate) as a starting point for new plugins.

## Centralized Logger System

**✅ CRITICAL: PenPal.Utils.BuildLogger for Consistent Plugin Logging**
PenPal provides a centralized logger system that automatically assigns unique colors to each plugin and provides consistent formatting across the entire system.

### Logger Features

**Automatic Color Assignment:**
- Each plugin gets a unique color based on a hash of the plugin name
- 12 ANSI colors available: cyan, green, yellow, blue, magenta, red, white, gray, bright versions
- Colors are consistent across server restarts for the same plugin name

**Plugin Name Prefixing:**
- Automatically adds colored `[PluginName]` prefix to all log messages
- Replaces manual console.log formatting with standardized approach
- Maintains existing timestamp format for compatibility

**Multiple Log Levels:**
- `logger.log()` - General information (white/default color)
- `logger.info()` - Informational messages (cyan)
- `logger.warn()` - Warning messages (yellow)
- `logger.error()` - Error messages (red)
- `logger.debug()` - Debug information (gray)

### Logger Implementation Pattern

**✅ CORRECT: File-Level Logger Export**
Create a shared logger that can be imported by any file within the plugin:

```javascript
// plugin.js - Main plugin file
import PenPal from "#penpal/core";

// File-level logger that can be imported by other files
export const YourPluginLogger = PenPal.Utils.BuildLogger("YourPlugin");

const YourPlugin = {
  async loadPlugin() {
    YourPluginLogger.log("Plugin loading started");
    
    // Plugin initialization code
    
    YourPluginLogger.log("Plugin loaded successfully");
    return { settings };
  },
};

export default YourPlugin;
```

**Using Logger in Other Plugin Files:**
```javascript
// other-file.js - API, utilities, etc.
import PenPal from "#penpal/core";

// Import the shared logger from plugin.js
import { YourPluginLogger as logger } from "./plugin.js";

export const performOperation = async () => {
  logger.log("Starting operation");
  
  try {
    // Operation logic
    logger.log("Operation completed successfully");
  } catch (error) {
    logger.error("Operation failed:", error.message);
    throw error;
  }
};
```

### Logger Migration Process

**Step 1: Create File-Level Logger Export**
```javascript
// Add to top of plugin.js after imports
export const YourPluginLogger = PenPal.Utils.BuildLogger("YourPlugin");
```

**Step 2: Replace Console Statements**
```javascript
// ❌ OLD: Manual console.log with prefixes
console.log("[YourPlugin] Starting scan");
console.error("[YourPlugin] Scan failed:", error);

// ✅ NEW: Use logger methods
logger.log("Starting scan");
logger.error("Scan failed:", error);
```

**Step 3: Remove Manual Prefixes**
Use sed or find-replace to remove plugin name prefixes since the logger handles them:
```bash
# Remove plugin name prefixes from all files
sed -i '' 's/\[YourPlugin\] //g' Plugins/YourPlugin/server/**/*.js
```

**Step 4: Import Logger in Other Files**
```javascript
// Import shared logger in API files, utilities, etc.
import { YourPluginLogger as logger } from "../plugin.js";
```

### Logger Output Examples

**Color-Coded Output:**
```
2024-01-15T10:30:45.123Z [Docker] Building image: penpal:httpx
2024-01-15T10:30:46.456Z [HttpX] Starting HTTP service scan
2024-01-15T10:30:47.789Z [JobsTracker] Created job: HTTP-SCAN-123
2024-01-15T10:30:48.012Z [CoreAPI] Added 15 service enrichments
```

**Different Log Levels:**
```javascript
logger.info("Configuration loaded");    // Cyan [PluginName]
logger.log("Processing started");       // White [PluginName]  
logger.warn("Deprecated API used");     // Yellow [PluginName]
logger.error("Connection failed");      // Red [PluginName]
logger.debug("Variable state:", obj);   // Gray [PluginName]
```

### Logger Best Practices

**Use Appropriate Log Levels:**
- `logger.log()` for general operational messages
- `logger.info()` for configuration and startup information
- `logger.warn()` for non-critical issues and deprecation notices
- `logger.error()` for failures and exceptions
- `logger.debug()` for detailed troubleshooting information

**Message Content Guidelines:**
- Remove plugin name prefixes (logger handles them automatically)
- Use clear, descriptive messages without redundant information
- Include relevant context like counts, IDs, or status
- For errors, include the error message or relevant details

**Performance Considerations:**
- Logger calls are synchronous and fast
- No need to conditionally disable logging in production
- Debug level can be controlled via environment variables if needed

**File Organization:**
- Always export logger from main plugin.js file
- Import logger consistently as `logger` or `YourPluginLogger as logger`
- Use the same logger instance across all files in a plugin

### Logger Implementation Details

**Color Assignment Algorithm:**
```javascript
// Simplified version of the color assignment
const colors = [
  '\x1b[36m', // cyan
  '\x1b[32m', // green  
  '\x1b[33m', // yellow
  '\x1b[34m', // blue
  '\x1b[35m', // magenta
  '\x1b[31m', // red
  // ... more colors
];

const hash = plugin_name.split('').reduce((a, b) => {
  a = ((a << 5) - a) + b.charCodeAt(0);
  return a & a;
}, 0);

const color = colors[Math.abs(hash) % colors.length];
```

**Message Format:**
```
{timestamp} {colored_plugin_prefix} {message}
2024-01-15T10:30:45.123Z [PluginName] Your log message here
```

### Migration Examples

**Before (Manual Console Logging):**
```javascript
// ❌ OLD: Inconsistent manual logging
console.log("[HttpX] Starting HTTP scan for", targets.length, "targets");
console.error("[HttpX] Scan failed:", error);
console.log("[+] HttpX scan completed successfully");
```

**After (Centralized Logger):**
```javascript
// ✅ NEW: Consistent logger usage
logger.log("Starting HTTP scan for", targets.length, "targets");
logger.error("Scan failed:", error);
logger.log("Scan completed successfully");
```

**Benefits of Migration:**
- **Consistent Formatting**: All plugins use the same timestamp and prefix format
- **Unique Colors**: Easy visual identification of different plugins in logs
- **Reduced Maintenance**: No manual prefix management or formatting
- **Better Debugging**: Clear plugin attribution for all log messages
- **Professional Output**: Clean, consistent logging across the entire system

## Plugin Communication
- **MQTT Plugin**: [Plugins/MQTT/server/plugin.js](mdc:Plugins/MQTT/server/plugin.js) - Inter-plugin messaging
- Plugins can subscribe to events like new hosts/networks discovery
- Job queue system for long-running tasks

### BatchFunction Utility - Event Batching

**✅ CRITICAL: PenPal.Utils.BatchFunction for MQTT Event Batching**
The `BatchFunction` utility allows plugins to batch rapid event calls together, preventing system overload during high-frequency operations like service discovery.

#### BatchFunction Usage

**Basic Pattern:**
```javascript
// ✅ CORRECT: Use BatchFunction to batch MQTT events
const batchedHandler = PenPal.Utils.BatchFunction(handler, timeoutMs);

// Subscribe with batched handler
await MQTT.Subscribe(
  PenPal.API.MQTT.Topics.New.Services,
  PenPal.Utils.BatchFunction(start_http_service_scan_batch, 5000)
);
```

**Function Signature:**
```javascript
PenPal.Utils.BatchFunction(handler, timeoutMs)
```

**Parameters:**
- `handler` - Function that will receive an array of batched argument sets
- `timeoutMs` - Timeout in milliseconds to wait after the last call before executing

**How It Works:**
1. **Collect Arguments**: Each function call adds its arguments to an internal array
2. **Reset Timer**: Each new call resets the timeout timer
3. **Execute Handler**: After `timeoutMs` of no new calls, executes the handler with all batched arguments
4. **Clear Batch**: Resets the argument array for the next batch

#### Real-World Example: HttpX Plugin

**Before (Individual Processing):**
```javascript
// ❌ Old pattern - processes each MQTT event separately
const start_http_service_scan = async ({ project, service_ids }) => {
  console.log("HttpX: New Services:", service_ids);
  // Process individual service discovery event
  // This could fire hundreds of times during a large scan
};

await MQTT.Subscribe(
  PenPal.API.MQTT.Topics.New.Services,
  start_http_service_scan
);
```

**After (Batched Processing):**
```javascript
// ✅ New pattern - batches multiple MQTT events together
const start_http_service_scan_batch = async (batchedArgs) => {
  console.log("HttpX: Processing batched events:", batchedArgs.length);
  
  // Collect all unique service IDs and projects from batched arguments
  const projectServiceMap = new Map();
  
  for (const [{ project, service_ids }] of batchedArgs) {
    if (!projectServiceMap.has(project)) {
      projectServiceMap.set(project, new Set());
    }
    service_ids.forEach(id => projectServiceMap.get(project).add(id));
  }
  
  // Process each project's services in bulk
  for (const [project, serviceIdSet] of projectServiceMap) {
    const service_ids = Array.from(serviceIdSet);
    await performBulkScan(project, service_ids);
  }
};

await MQTT.Subscribe(
  PenPal.API.MQTT.Topics.New.Services,
  PenPal.Utils.BatchFunction(start_http_service_scan_batch, 5000)
);
```

#### BatchFunction Benefits

**Performance Improvements:**
- **Reduced Load**: Prevents overwhelming the system during rapid events
- **Deduplication**: Automatically handles duplicate service IDs
- **Bulk Processing**: Enables efficient batch operations
- **Resource Optimization**: Reduces Docker container spawning and job creation

**Use Cases:**
- **MQTT Event Bursts**: Service/host discovery events during large scans
- **Database Operations**: Batching multiple inserts/updates
- **External API Calls**: Reducing API rate limit issues
- **Container Operations**: Minimizing Docker container overhead

**Configuration Guidelines:**
- **Short Timeouts (1-2s)**: For real-time operations requiring quick response
- **Medium Timeouts (5-10s)**: For service discovery and enrichment (recommended)
- **Long Timeouts (30s+)**: For non-critical background processing

#### Advanced BatchFunction Patterns

**Multi-Project Deduplication:**
```javascript
const batchedHandler = async (batchedArgs) => {
  // Group by project and deduplicate service IDs
  const projectServiceMap = new Map();
  
  for (const [{ project, service_ids }] of batchedArgs) {
    if (!projectServiceMap.has(project)) {
      projectServiceMap.set(project, new Set());
    }
    service_ids.forEach(id => projectServiceMap.get(project).add(id));
  }
  
  // Process each project separately
  for (const [project, serviceIds] of projectServiceMap) {
    await processProject(project, Array.from(serviceIds));
  }
};
```

**Error Handling:**
```javascript
const robustBatchedHandler = async (batchedArgs) => {
  try {
    console.log(`Processing ${batchedArgs.length} batched events`);
    
    // Group and process events
    const results = await processBatchedEvents(batchedArgs);
    
    console.log(`Successfully processed ${results.length} items`);
  } catch (error) {
    console.error("Batch processing failed:", error);
    
    // Fallback to individual processing if batch fails
    for (const [args] of batchedArgs) {
      try {
        await processIndividual(args);
      } catch (individualError) {
        console.error("Individual processing failed:", individualError);
      }
    }
  }
};
```

**Monitoring and Metrics:**
```javascript
const monitoredBatchedHandler = async (batchedArgs) => {
  const startTime = Date.now();
  const eventCount = batchedArgs.length;
  const totalServices = batchedArgs.reduce((sum, [{ service_ids }]) => sum + service_ids.length, 0);
  
  console.log(`[Batch] Processing ${eventCount} events with ${totalServices} total services`);
  
  try {
    await processBatchedEvents(batchedArgs);
    
    const duration = Date.now() - startTime;
    console.log(`[Batch] Completed in ${duration}ms (${(totalServices/duration*1000).toFixed(1)} services/sec)`);
  } catch (error) {
    console.error(`[Batch] Failed after ${Date.now() - startTime}ms:`, error);
    throw error;
  }
};
```

#### Migration to BatchFunction

**Step 1: Identify Batching Candidates**
- MQTT event handlers that process rapid events
- Functions called repeatedly with similar arguments
- Operations that benefit from bulk processing

**Step 2: Modify Handler Signature**
```javascript
// Before: Single argument set
const handler = async ({ project, service_ids }) => { /* ... */ };

// After: Array of argument sets
const batchedHandler = async (batchedArgs) => {
  for (const [{ project, service_ids }] of batchedArgs) {
    // Process each argument set
  }
};
```

**Step 3: Apply BatchFunction**
```javascript
// Wrap handler with BatchFunction
const wrappedHandler = PenPal.Utils.BatchFunction(batchedHandler, 5000);

// Use in MQTT subscription
await MQTT.Subscribe(topic, wrappedHandler);
```

**Step 4: Test and Tune**
- Monitor batch sizes and processing times
- Adjust timeout based on use case requirements
- Verify deduplication works correctly
- Test error handling scenarios

The `BatchFunction` utility is essential for building scalable plugins that can handle high-frequency events without overwhelming system resources.

## Docker Plugin - Container Orchestration

**✅ CRITICAL: Docker Plugin for Microservices**
The Docker plugin provides essential container orchestration capabilities for running cybersecurity tools in isolated environments. It's fundamental for plugins like Nmap, HttpX, and other security tools.

### Docker Plugin Configuration

**Docker Settings in plugin.js:**
```javascript
// ✅ CORRECT Docker configuration patterns
export const settings = {
  docker: {
    name: "penpal:toolname",                    // Container image name
    dockercontext: `${__dirname}/docker-context`, // Build context path
    // OR for pre-built images:
    // image: "existing/image:tag"              // Pull existing image
  },
};

// ❌ WRONG - Don't mix image and dockerfile/dockercontext
export const settings = {
  docker: {
    name: "penpal:toolname",
    dockercontext: "./docker-context",
    image: "conflicting/image"  // Causes validation error
  },
};
```

### Docker API Methods

**Container Lifecycle Management:**
```javascript
// ✅ Run containers with proper isolation
const result = await PenPal.Docker.Run({
  image: "penpal:httpx",
  cmd: "httpx -l /input/targets.txt -o /output/results.json",
  daemonize: true,                    // Run in background
  network: "penpal_penpal",          // Use PenPal network
  volume: {                          // Mount shared volume
    name: "penpal_penpal-plugin-share",
    path: "/penpal-plugin-share"
  }
});

// Get container ID and wait for completion
const container_id = result.stdout.trim();
await PenPal.Docker.Wait(container_id);
```

**Volume Management:**
```javascript
// ✅ CORRECT Volume patterns for file I/O
const volume = {
  name: "penpal_penpal-plugin-share",  // Shared volume name
  path: "/penpal-plugin-share"         // Container mount path
};

// Use volume paths that work with mounts
const host_file = "/penpal-plugin-share/httpx/project1/targets.txt";
const container_file = host_file.replace("/penpal-plugin-share", "/penpal-plugin-share");

// ❌ WRONG - Don't use hardcoded paths
const bad_path = "/tmp/local-file.txt";  // Won't be accessible in container
```

**Container Commands:**
```javascript
// Available Docker operations
await PenPal.Docker.Start(container_id);           // Start stopped container
await PenPal.Docker.Stop(container_id);            // Stop running container
await PenPal.Docker.Wait(container_id);            // Wait for completion
await PenPal.Docker.Exec({ container, cmd });      // Execute in running container
await PenPal.Docker.Copy({ container, container_file, output_file }); // Copy files
await PenPal.Docker.RemoveContainer(container_id); // Clean up container
await PenPal.Docker.Raw(docker_command);           // Execute raw docker command
```

### Docker Build Process

**✅ CRITICAL: Background Image Building**
The Docker plugin builds images in the background during startup to avoid blocking server initialization. This allows the GraphQL server to start immediately while Docker builds happen asynchronously.

```javascript
// Docker plugin validates settings and builds images
const check_docker = (docker) => {
  // Validates docker configuration
  // Ensures either image OR dockerfile/dockercontext is specified
  // Checks for required fields (name, etc.)
};

const build_docker_images = async () => {
  // Returns immediately to not block startup
  // Starts background building process
  // Images tracked with Jobs API for progress monitoring
};
```

**Background Build Status Tracking:**
```javascript
// ✅ Check if Docker images are ready before using them
if (PenPal.Docker.IsImageReady("penpal:httpx")) {
  // Image is built and ready to use
  await performContainerizedScan();
} else if (PenPal.Docker.IsImageBuilding("penpal:httpx")) {
  // Image is currently building in background
  console.log("Waiting for Docker image to build...");
} else if (PenPal.Docker.IsImageFailed("penpal:httpx")) {
  // Image build failed
  console.error("Docker image build failed");
}

// ✅ RECOMMENDED: Use helper function to wait for image readiness
await PenPal.Docker.WaitForImageReady("penpal:httpx", {
  updateCallback: update_job, // Optional progress callback
  updateMessage: "Waiting for HttpX Docker image to build...",
  timeout: 120000 // Optional timeout in ms (default: 2 minutes)
});

// Get complete build status
const buildStatus = PenPal.Docker.GetBuildStatus();
console.log("Pending builds:", buildStatus.pending);
console.log("Currently building:", buildStatus.building);
console.log("Completed builds:", buildStatus.completed);
console.log("Failed builds:", buildStatus.failed);
```

**Background Build Benefits:**
- **Faster Server Startup**: GraphQL server starts immediately
- **Non-blocking**: Long Docker builds don't delay application availability
- **Progress Tracking**: All builds tracked as Jobs with real-time progress
- **Parallel Building**: Multiple images build simultaneously
- **Error Handling**: Failed builds don't crash the server

**Dockerfile Best Practices:**
```dockerfile
# ✅ Multi-stage builds for security tools
FROM golang:1.21-alpine AS builder
WORKDIR /app
RUN go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /go/bin/httpx .
ENTRYPOINT ["./httpx"]
```

### Integration Patterns

**MQTT-Triggered Container Execution:**
```javascript
// ✅ Standard pattern for event-driven security tools
const HttpXPlugin = {
  async loadPlugin() {
    const MQTT = await PenPal.MQTT.NewClient();
    
    // Subscribe to service discovery events
    await MQTT.Subscribe(
      PenPal.API.MQTT.Topics.New.Services,
      async ({ project, service_ids }) => {
        // Filter services for HTTP scanning candidates
        const services = await PenPal.API.Services.GetMany(service_ids);
        const tcp_services = services.filter(s => 
          s.ip_protocol === "TCP" && s.status === "open"
        );
        
        if (tcp_services.length > 0) {
          await performContainerizedScan(tcp_services);
        }
      }
    );
    
    return { settings };
  },
};
```

**File-Based Container Communication:**
```javascript
// ✅ Use shared volumes for input/output
export const performHttpScan = async ({ services, project_id }) => {
  const outdir = "/penpal-plugin-share/httpx/" + project_id;
  PenPal.Utils.MkdirP(outdir);
  
  // Create input file for container
  const targets_file = path.join(outdir, `targets-${PenPal.Utils.Epoch()}.txt`);
  const targets = services.map(s => `http://${s.host_ip}:${s.port}`);
  fs.writeFileSync(targets_file, targets.join('\n'));
  
  // Create output file path
  const output_file = path.join(outdir, `results-${PenPal.Utils.Epoch()}.json`);
  
  // Convert to container paths
  const container_targets = targets_file.replace("/penpal-plugin-share", "/penpal-plugin-share");
  const container_output = output_file.replace("/penpal-plugin-share", "/penpal-plugin-share");
  
  // Run containerized tool
  const result = await PenPal.Docker.Run({
    image: settings.docker.name,
    cmd: `-l ${container_targets} -o ${container_output} -json`,
    daemonize: true,
    volume: { name: "penpal_penpal-plugin-share", path: "/penpal-plugin-share" },
    network: "penpal_penpal"
  });
  
  // Wait and process results
  await PenPal.Docker.Wait(result.stdout.trim());
  const results = fs.readFileSync(output_file, 'utf8');
  return JSON.parse(results);
};
```

### Security and Isolation

**Network Isolation:**
- All containers run in `penpal_penpal` network
- Isolated from host network by default
- Can communicate with other PenPal services

**Volume Security:**
- Shared volumes use specific mount points
- No access to host filesystem outside mounted volumes
- Temporary files automatically cleaned up

**Resource Management:**
- Containers are ephemeral and cleaned up after use
- No persistent state in containers
- Resource limits can be enforced

### Docker Plugin Dependencies

**Required Dependencies:**
```json
{
  "name": "YourSecurityTool",
  "dependsOn": ["CoreAPI@0.1.0", "Docker@0.1.0", "JobsTracker@0.1.0"]
}
```

**Docker Host Configuration:**
- Requires Docker daemon accessible at `penpal-docker-api:2376`
- Uses Docker Compose for orchestration
- Supports both image pulling and local building

## Jobs API - Centralized Job Management

The **JobsTracker Plugin** provides a centralized job management system for long-running tasks across all plugins. This replaces the need for individual plugins to manage their own job queues.

### Jobs API Usage

**✅ CRITICAL: Jobs API Signature**
All Jobs operations are available through the `PenPal.Jobs` object:

```javascript
// ✅ CORRECT Jobs API usage
const job = await PenPal.Jobs.Create(jobData);
await PenPal.Jobs.Update(job_id, updates);
await PenPal.Jobs.UpdateProgress(job_id, progress);
await PenPal.Jobs.UpdateStage(job_id, stage_index, updates);
const job = await PenPal.Jobs.Get(job_id);
const jobs = await PenPal.Jobs.GetAll();
const filtered = await PenPal.Jobs.GetFiltered(filterMode);

// ❌ WRONG - Common API naming mistakes
await PenPal.JobsTracker.insertJob(); // Use PenPal.Jobs.Create() instead
await PenPal.JobsTracker.updateJob(); // Use PenPal.Jobs.Update() instead
await PenPal.JobsTracker.updateJobStage(); // Use PenPal.Jobs.UpdateStage() instead
const jobs = []; // Local job arrays - use centralized API instead
const job_id = "manual-id"; // Manual ID generation - let API handle IDs
```

### Job Structure

**Basic Job Fields:**
```javascript
const jobData = {
  name: "Descriptive Job Name",
  plugin: "YourPluginName", // Auto-populated if not provided
  statusText: "Initial status message",
  progress: 0, // 0-100 percentage
  status: "running", // running, done, failed, cancelled
  // Optional fields:
  stages: [/* array of stage objects */],
};
```

**Job with Stages:**
```javascript
const jobWithStages = {
  name: "Multi-Stage Job",
  plugin: "YourPluginName",
  statusText: "Starting multi-stage process",
  progress: 0,
  stages: [
    {
      name: "Stage 1: Preparation",
      statusText: "Preparing environment",
      progress: 0,
      status: "pending"
    },
    {
      name: "Stage 2: Execution", 
      statusText: "Running main process",
      progress: 0,
      status: "pending"
    },
    {
      name: "Stage 3: Cleanup",
      statusText: "Cleaning up resources",
      progress: 0,
      status: "pending"
    }
  ]
};
```

### ⚠️ CRITICAL: Jobs API Naming Convention

**✅ ALWAYS use `PenPal.Jobs`, NEVER `PenPal.JobsTracker`**

```javascript
// ✅ CORRECT - Use PenPal.Jobs namespace
await PenPal.Jobs.Create(jobData);
await PenPal.Jobs.Update(job_id, updates);
await PenPal.Jobs.UpdateStage(job_id, stage_index, updates);

// ❌ WRONG - Don't use PenPal.JobsTracker
await PenPal.JobsTracker.insertJob(jobData);     // INCORRECT API NAME
await PenPal.JobsTracker.updateJob(job_id, data); // INCORRECT API NAME
await PenPal.JobsTracker.updateJobStage(job_id, stage, data); // INCORRECT API NAME

// ❌ WRONG - Don't try to access JobsTracker directly
PenPal.JobsTracker = PenPal.Plugins.JobsTracker.API; // NOT NEEDED
```

The JobsTracker plugin exposes its API through the `PenPal.Jobs` namespace automatically. Do not attempt to manually set up API access in your plugin's `loadPlugin()` function.

### Jobs API Methods

**Create Job:**
```javascript
// Simple job without stages
const job = await PenPal.Jobs.Create({
  name: "Network Scan",
  statusText: "Starting network scan",
  progress: 0
});

// Job with stages
const job = await PenPal.Jobs.Create(jobWithStages);
```

**Update Job:**
```javascript
// Update job progress and status
await PenPal.Jobs.Update(job.id, {
  progress: 50,
  statusText: "Halfway complete"
});

// Mark job as complete
await PenPal.Jobs.Update(job.id, {
  progress: 100,
  status: "done",
  statusText: "Scan complete"
});
```

**Update Job Progress (Convenience Method):**
```javascript
// Quick progress update
await PenPal.Jobs.UpdateProgress(job.id, 75);
```

**Update Job Stage:**
```javascript
// Update specific stage by index (0-based)
await PenPal.Jobs.UpdateStage(job.id, 0, {
  progress: 100,
  status: "done",
  statusText: "Preparation complete"
});

// Start next stage
await PenPal.Jobs.UpdateStage(job.id, 1, {
  progress: 0,
  status: "running",
  statusText: "Beginning execution"
});
```

**Retrieve Jobs:**
```javascript
// Get specific job
const job = await PenPal.Jobs.Get(job_id);

// Get all jobs
const allJobs = await PenPal.Jobs.GetAll();

// Get filtered jobs
const activeJobs = await PenPal.Jobs.GetFiltered("active");
const recentJobs = await PenPal.Jobs.GetFiltered("recent");
```

### Job Management Best Practices

**Job Lifecycle Management:**
```javascript
// 1. Create job
const job = await PenPal.Jobs.Create({
  name: "Host Discovery Scan",
  statusText: "Initializing scan parameters",
  progress: 0
});

try {
  // 2. Update progress during execution
  await PenPal.Jobs.UpdateProgress(job.id, 25);
  await performScanStep1();
  
  await PenPal.Jobs.Update(job.id, {
    progress: 50,
    statusText: "Scanning network ranges"
  });
  await performScanStep2();
  
  // 3. Complete successfully
  await PenPal.Jobs.Update(job.id, {
    progress: 100,
    status: PenPal.Jobs.Status.DONE,
    statusText: "Scan completed successfully"
  });
  
} catch (error) {
  // 4. Handle failures
  await PenPal.Jobs.Update(job.id, {
    status: PenPal.Jobs.Status.FAILED,
    statusText: `Scan failed: ${error.message}`
  });
}
```

**Multi-Stage Job Management:**
```javascript
const job = await PenPal.Jobs.Create({
  name: "Comprehensive Security Scan",
  stages: [
    { name: "Port Scan", statusText: "Scanning ports", progress: 0, status: PenPal.Jobs.Status.PENDING },
    { name: "Service Detection", statusText: "Detecting services", progress: 0, status: PenPal.Jobs.Status.PENDING },
    { name: "Vulnerability Assessment", statusText: "Checking vulnerabilities", progress: 0, status: PenPal.Jobs.Status.PENDING }
  ]
});

// Execute stage 1
await PenPal.Jobs.UpdateStage(job.id, 0, { status: PenPal.Jobs.Status.RUNNING });
await performPortScan();
await PenPal.Jobs.UpdateStage(job.id, 0, { 
  progress: 100, 
  status: PenPal.Jobs.Status.DONE,
  statusText: "Port scan complete"
});

// Execute stage 2
await PenPal.Jobs.UpdateStage(job.id, 1, { status: PenPal.Jobs.Status.RUNNING });
await performServiceDetection();
await PenPal.Jobs.UpdateStage(job.id, 1, { 
  progress: 100, 
  status: PenPal.Jobs.Status.DONE,
  statusText: "Service detection complete"
});

// Update overall job progress
await PenPal.Jobs.UpdateProgress(job.id, 100);
```

### Integration with Security Tools

**Example: Nmap Integration**
```javascript
// Replace local job management with Jobs API
export const start_detailed_hosts_scan = async (hosts) => {
  const job = await PenPal.Jobs.Create({
    name: `Detailed Host Scan for ${hosts.length} hosts`,
    statusText: "Preparing detailed scan",
    progress: 0,
    stages: [
      { name: "Port Scan", statusText: "Scanning ports", progress: 0, status: PenPal.Jobs.Status.PENDING },
      { name: "Service Detection", statusText: "Detecting services", progress: 0, status: PenPal.Jobs.Status.PENDING },
      { name: "OS Detection", statusText: "Identifying operating systems", progress: 0, status: PenPal.Jobs.Status.PENDING }
    ]
  });

  // Pass job_id to scan function instead of job_stages
  performScan(hosts, job.id);
  return job.id;
};
```

### Job Status and Filtering

**✅ CRITICAL: Standardized Job Status Constants**
Always use the predefined status constants to ensure consistency:

```javascript
// ✅ CORRECT Status constants
PenPal.Jobs.Status.PENDING    // "pending" - Job is queued/waiting
PenPal.Jobs.Status.RUNNING    // "running" - Job is actively executing  
PenPal.Jobs.Status.DONE       // "done" - Job completed successfully
PenPal.Jobs.Status.FAILED     // "failed" - Job failed with error
PenPal.Jobs.Status.CANCELLED  // "cancelled" - Job was cancelled

// ✅ CORRECT Check if status is completed
const isCompleted = PenPal.Jobs.CompletedStatuses.includes(job.status);

// ❌ WRONG - Don't use hardcoded status strings
status: "completed" // Invalid status - use PenPal.Jobs.Status.DONE
status: "finished"  // Invalid status - use PenPal.Jobs.Status.DONE
status: "running"   // Use PenPal.Jobs.Status.RUNNING instead
```

**Job Status Values:**
- `PenPal.Jobs.Status.PENDING` - Job is queued/waiting to start
- `PenPal.Jobs.Status.RUNNING` - Job is currently executing
- `PenPal.Jobs.Status.DONE` - Job completed successfully
- `PenPal.Jobs.Status.FAILED` - Job encountered an error
- `PenPal.Jobs.Status.CANCELLED` - Job was manually cancelled

**Filter Modes:**
- `"active"` - Shows running jobs and recent completed jobs (default UI view)
- `"recent"` - Shows jobs from the last 24 hours
- `"all"` - Shows all jobs with pagination

### Automatic Job Cleanup

The JobsTracker automatically cleans up stale jobs:
- Jobs not updated for 5+ minutes are marked as "cancelled"
- Cleanup runs every 5 minutes automatically
- Prevents accumulation of orphaned jobs from crashed processes

### UI Integration

The JobsTracker provides a comprehensive UI at `/jobs` with:
- **Real-time job monitoring** with 500ms polling
- **Progress visualization** with color-coded progress bars
- **Stage-by-stage tracking** for complex jobs
- **Filtering and pagination** for job history
- **Runtime and completion time tracking**
- **Automatic cleanup** of stale jobs

### Migration from Local Job Management

**Before (Local Job Management):**
```javascript
// ❌ Old pattern - local job arrays
const jobs = [];
const job_id = generateId();
jobs.push({ id: job_id, name: "Scan", progress: 0 });
```

**After (Jobs API):**
```javascript
// ✅ New pattern - centralized Jobs API
const job = await PenPal.Jobs.Create({
  name: "Scan",
  progress: 0
});
```

The Jobs API provides better reliability, persistence, monitoring, and user experience compared to local job management.

## GraphQL Integration
Plugins extend the GraphQL schema with:
- Custom types and mutations
- Resolvers and data loaders  
- Schema stitching via plugin loading system
- **Real-time subscriptions** via WebSocket

### GraphQL Subscriptions & Real-time Updates

**✅ CRITICAL: WebSocket Subscription Support**
PenPal supports real-time GraphQL subscriptions using WebSocket transport while maintaining full Apollo Client compatibility.

#### Server-Side Subscription Setup

**PubSub System:**
```javascript
// PubSub is automatically available in all plugins
export const updateItem = async (item_id, updates) => {
  const result = await PenPal.DataStore.updateOne("PluginName", "Items", { id: item_id }, updates);
  
  // Publish real-time update
  if (PenPal.PubSub) {
    const updatedItem = await getItem(item_id);
    PenPal.PubSub.publish('ITEM_UPDATED', { itemUpdated: updatedItem });
  }
  
  return result;
};
```

**Subscription Schema:**
```graphql
# plugin/graphql/schema/subscriptions.graphql
extend type Subscription {
  itemUpdated: Item
  itemCreated: Item
  itemDeleted: ID
}
```

**Subscription Resolvers:**
```javascript
// plugin/graphql/resolvers/subscriptions.js
export default {
  async itemUpdated(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_UPDATED']);
  },
  
  async itemCreated(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_CREATED']);
  },
  
  async itemDeleted(parent, args, { pubsub }) {
    return pubsub.asyncIterator(['ITEM_DELETED']);
  },
};
```

**✅ CRITICAL: Correct Subscription Resolver Pattern**

GraphQL subscription resolvers MUST use the **object pattern with `subscribe` method**, not direct function patterns:

```javascript
// ✅ CORRECT: Object resolvers with subscribe method
export default {
  jobUpdated: {
    subscribe: (parent, args, context) => {
      if (!context?.pubsub) {
        throw new Error("PubSub not available in subscription context");
      }
      return context.pubsub.asyncIterator(["JOB_UPDATED"]);
    }
  },
  
  jobCreated: {
    subscribe: (parent, args, context) => {
      return context.pubsub.asyncIterator(["JOB_CREATED"]);
    }
  },
  
  activeJobsChanged: {
    subscribe: (parent, args, context) => {
      return context.pubsub.asyncIterator(["ACTIVE_JOBS_CHANGED"]);
    }
  }
};

// ❌ WRONG: Direct function resolvers (will fail with "must return Async Iterable" error)
export default {
  async jobUpdated(parent, args, context) {
    return context.pubsub.asyncIterator(["JOB_UPDATED"]); // This pattern doesn't work!
  }
};
```

**Why This Matters:**
- GraphQL requires subscription resolvers to return async iterables
- The function pattern fails with "Subscription field must return Async Iterable. Received: undefined."
- The object pattern with `subscribe` method is the GraphQL specification standard
- Using the wrong pattern causes WebSocket disconnections with 4500 error codes

**Debugging Subscription Issues:**
If subscriptions fail with "Internal error occurred during message handling", check:
1. **Resolver Pattern**: Use object resolvers with `subscribe` method
2. **PubSub Availability**: Ensure `context.pubsub` is available in WebSocket context
3. **AsyncIterator Creation**: Verify `pubsub.asyncIterator()` succeeds
4. **Schema Registration**: Confirm subscription resolvers are properly exported

**Resolver Registration:**
```javascript
// plugin/graphql/resolvers.js
export default [
  {
    Query: { ...resolvers.queries },
    Mutation: { ...resolvers.mutations },
    Subscription: { ...resolvers.subscriptions }, // Add subscriptions
  },
  ...resolvers.default_resolvers,
  ...resolvers.scalars,
];
```

#### Client-Side Subscription Usage

**Subscription Query:**
```javascript
// plugin/client/queries/item-subscription.js
import { gql } from "@apollo/client";

const ITEM_UPDATED_SUBSCRIPTION = gql`
  subscription ItemUpdated {
    itemUpdated {
      id
      name
      status
      updated_at
    }
  }
`;

export default ITEM_UPDATED_SUBSCRIPTION;
```

**React Component with Subscriptions:**
```javascript
import React, { useState, useEffect } from "react";
import { useQuery, useSubscription } from "@apollo/client";

const ItemComponent = () => {
  const [items, setItems] = useState([]);

  // Initial query
  const { data, loading } = useQuery(GET_ITEMS, {
    onCompleted: (data) => setItems(data?.getItems || []),
  });

  // Real-time subscription
  const { data: subscriptionData } = useSubscription(ITEM_UPDATED_SUBSCRIPTION, {
    onData: ({ data }) => {
      if (data?.data?.itemUpdated) {
        const updatedItem = data.data.itemUpdated;
        setItems(prev => prev.map(item => 
          item.id === updatedItem.id ? updatedItem : item
        ));
      }
    },
    onError: (error) => {
      console.warn("Subscription error, falling back to polling:", error);
    },
  });

  // Fallback polling if subscription fails
  useEffect(() => {
    if (subscriptionData?.error) {
      const interval = setInterval(() => {
        // Refetch data as fallback
      }, 5000);
      return () => clearInterval(interval);
    }
  }, [subscriptionData]);

  return (
    <div>
      {items.map(item => (
        <div key={item.id}>{item.name} - {item.status}</div>
      ))}
    </div>
  );
};
```

#### WebSocket Configuration

**Server WebSocket Setup:**
The GraphQL server automatically configures WebSocket support:
- **WebSocket endpoint**: `ws://localhost:3001/graphql`
- **HTTP endpoint**: `http://localhost:3001/graphql`
- **Split transport**: Subscriptions via WebSocket, queries/mutations via HTTP

**Client Apollo Configuration:**
Apollo Client is pre-configured with split link transport:
```javascript
// Automatic split: subscriptions use WebSocket, queries/mutations use HTTP
const apollo_client = new ApolloClient({
  cache,
  link: splitLink, // Automatically routes based on operation type
});
```

#### Common Subscription Patterns

**Real-time Job Updates (JobsTracker Example):**
```javascript
// Server: Publish job updates
export const updateJob = async (job_id, updates) => {
  const result = await PenPal.DataStore.updateOne("JobsTracker", "Jobs", { id: job_id }, updates);
  
  // Real-time notification
  if (PenPal.PubSub) {
    const updatedJob = await getJob(job_id);
    PenPal.PubSub.publish('JOB_UPDATED', { jobUpdated: updatedJob });
    
    // Aggregate updates
    const activeJobs = await getActiveJobs();
    PenPal.PubSub.publish('ACTIVE_JOBS_CHANGED', { activeJobsChanged: activeJobs });
  }
  
  return result;
};

// Client: Subscribe to job changes
const { data } = useSubscription(ACTIVE_JOBS_SUBSCRIPTION, {
  onData: ({ data }) => {
    if (data?.data?.activeJobsChanged) {
      setActiveJobs(data.data.activeJobsChanged);
    }
  },
});
```

**Service Discovery Updates:**
```javascript
// Server: Publish service discoveries
PenPal.PubSub.publish('NEW_SERVICES_DISCOVERED', { 
  newServicesDiscovered: { project_id, services } 
});

// Client: Real-time service updates
const { data } = useSubscription(SERVICE_DISCOVERY_SUBSCRIPTION, {
  variables: { projectId },
  onData: ({ data }) => {
    if (data?.data?.newServicesDiscovered) {
      // Update UI immediately
      addNewServices(data.data.newServicesDiscovered.services);
    }
  },
});
```

#### Subscription Best Practices

**Event Naming Conventions:**
- Use UPPER_SNAKE_CASE for event names
- Include context: `JOB_UPDATED`, `SERVICE_DISCOVERED`, `HOST_SCAN_COMPLETE`
- Group related events: `ACTIVE_JOBS_CHANGED` aggregates multiple job events

**Error Handling:**
- Always implement subscription error handlers
- Provide fallback to polling for reliability
- Log subscription errors for debugging

**Performance Considerations:**
- Use aggregated subscriptions (e.g., `activeJobsChanged`) instead of individual item subscriptions
- Implement proper subscription cleanup in React components
- Consider subscription filtering on server-side for large datasets

**Security & Context:**
- Subscriptions inherit the same authentication context as queries/mutations
- PubSub events are server-wide - filter sensitive data appropriately
- Consider user-specific subscriptions for multi-tenant scenarios

#### WebSocket vs Polling

**Use Subscriptions For:**
- Real-time status updates (jobs, scans, discoveries)
- Live dashboards and monitoring
- Collaborative features
- Critical alerts and notifications

**Use Polling For:**
- One-time data fetching
- Backup/fallback scenarios
- Non-critical periodic updates
- Client-side state management

## DataStore API Usage

**✅ CRITICAL: DataStore API Signature**
All DataStore operations require **plugin name** and **store name** as first two parameters:

```javascript
// ✅ CORRECT DataStore API usage
await PenPal.DataStore.fetch("PluginName", "StoreName", query);
await PenPal.DataStore.fetchOne("PluginName", "StoreName", query);
await PenPal.DataStore.insertMany("PluginName", "StoreName", [data]);
await PenPal.DataStore.updateOne("PluginName", "StoreName", query, updates);
await PenPal.DataStore.delete("PluginName", "StoreName", query);

// ❌ WRONG - These methods don't exist
await PenPal.DataStore.getAll("StoreName");
await PenPal.DataStore.get("StoreName", id);
await PenPal.DataStore.insert("StoreName", data);
```

**DataStore Configuration in plugin.js:**
```javascript
const settings = {
  datastores: [
    {
      name: "YourStoreName", // This becomes the "StoreName" parameter
    },
  ],
};
```

**Common DataStore Patterns:**
- **Single Record**: `fetchOne("Plugin", "Store", { id: "some-id" })`
- **Multiple Records**: `fetch("Plugin", "Store", { status: "active" })`
- **Query by Array**: `fetch("Plugin", "Store", { id: { $in: [id1, id2] } })`
- **Insert Single**: `insertMany("Plugin", "Store", [singleRecord])[0]`
- **Update**: `updateOne("Plugin", "Store", { id: "some-id" }, updateData)`
- **Delete**: `delete("Plugin", "Store", { id: "some-id" })`

## GraphQL Schema Conflicts

**✅ Avoiding Type Conflicts:**
- Check existing GraphQL types before creating new ones
- Use unique type names prefixed with plugin name if needed
- Remove conflicting types from Base plugin when migrating functionality

**Common Conflict Scenarios:**
```graphql
# ❌ This will cause conflicts if Job type already exists elsewhere
type Job {
  id: ID!
  name: String!
}

# ✅ Use plugin-specific prefixes if conflicts arise
type JobsTrackerJob {
  id: ID!
  name: String!
}
```

**Scalar Type Usage:**
- Use existing scalars like `JSON` instead of `JSONObject`
- Check [PenPal/app/src/server/graphql/schema/scalars.graphql](mdc:PenPal/app/src/server/graphql/schema/scalars.graphql) for available types
- Consistent scalar usage prevents "Unknown type" errors

## Plugin Development Best Practices

**API Layer Structure:**
```javascript
// api/index.js - Clean separation of concerns
export const getItems = async (item_id) => {
  return await PenPal.DataStore.fetchOne("PluginName", "Items", { id: item_id });
};

export const insertItem = async (item_data) => {
  const item_with_timestamps = {
    ...item_data,
    id: item_data.id || PenPal.Utils.UUID(),
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
  };
  const result = await PenPal.DataStore.insertMany("PluginName", "Items", [item_with_timestamps]);
  return result[0];
};
```

**Plugin Registration Pattern:**
```javascript
// plugin.js - Register APIs on PenPal object
PenPal.YourAPI = {
  Get: API.getItem,
  Insert: API.insertItem,
  Update: API.updateItem,
  // Helper functions
  Create: async (itemData) => { /* convenience wrapper */ },
};
```

**Dependency Management:**
- Always specify plugin dependencies in manifest.json
- Use `"load": false` temporarily during development to prevent loading
- DataStore-dependent plugins must list `"DataStore@0.1.0"` in dependencies
- Docker-dependent plugins must list `"Docker@0.1.0"` in dependencies

**Migration Considerations:**
- When moving functionality from one plugin to another, update both GraphQL schemas
- Remove old resolvers and types to prevent conflicts
- Update client-side GraphQL queries to use new endpoints
- Consider backward compatibility for existing data

**Testing DataStore Integration:**
- Test with empty database first
- Verify all CRUD operations work correctly
- Check query syntax with MongoDB-style operators (`$in`, `$lt`, etc.)
- Ensure proper error handling for missing records

**Client-Server Plugin Coordination:**
- Client plugins should mirror server plugin structure
- Use consistent naming between client queries and server resolvers
- Implement proper loading states and error handling in React components
- Consider real-time updates with polling or subscriptions

**Logger Integration:**
- Always use the centralized logger system for consistent, colored output
- Create file-level logger exports that can be imported across plugin files
- Replace all console.log statements with appropriate logger methods
- Remove manual plugin name prefixes since the logger handles them automatically

## Lessons Learned from Plugin Development

### MQTT-Triggered Plugin Pattern

**✅ Service Discovery Chain:**
The HttpX plugin demonstrates the standard pattern for chained service discovery:

```javascript
// ✅ CORRECT Pattern for service-triggered plugins
const HttpXPlugin = {
  async loadPlugin() {
    const MQTT = await PenPal.MQTT.NewClient();
    
    // Subscribe to upstream service discovery events
    await MQTT.Subscribe(
      PenPal.API.MQTT.Topics.New.Services,
      async ({ project, service_ids }) => {
        // Filter for relevant services
        const services = await PenPal.API.Services.GetMany(service_ids);
        const candidates = services.filter(service => 
          service.ip_protocol === "TCP" && 
          service.status === "open" &&
          service.port
        );
        
        if (candidates.length > 0) {
          await performToolSpecificScan(candidates);
        }
      }
    );
  },
};
```

### Service Enrichment Pattern

**✅ Standardized Enrichment Workflow:**
```javascript
// ✅ CORRECT Service enrichment pattern
export const parseAndUpsertResults = async (project_id, services_data, output_data) => {
  const results = parseToolOutput(output_data);
  const service_updates = [];
  
  for (const result of results) {
    // Match results to original services
    const matching_service = services_data.find(service => 
      service.host_ip === result.host && service.port === result.port
    );
    
    if (matching_service) {
      // Create plugin-specific enrichment
      const enrichment = {
        plugin_name: "YourPlugin",
        // Tool-specific fields
        ...result
      };
      
      // Append to existing enrichments
      const updated_enrichments = [
        ...(matching_service.enrichments || []),
        enrichment
      ];
      
      service_updates.push({
        id: matching_service.id,
        enrichments: updated_enrichments
      });
    }
  }
  
  // Bulk update services
  if (service_updates.length > 0) {
    await PenPal.API.Services.UpsertMany(service_updates);
  }
};
```

### Host IP Resolution Pattern

**✅ Host Data Enrichment:**
```javascript
// ✅ CORRECT Pattern for resolving host IPs
const network_services = services.filter(/* filtering logic */);

// Get host information for services
const hosts_map = {};
for (const service of network_services) {
  if (service.host && !hosts_map[service.host]) {
    const host_data = await PenPal.API.Hosts.GetOne(service.host);
    hosts_map[service.host] = host_data;
    service.host_ip = host_data?.ip_address;
  } else if (hosts_map[service.host]) {
    service.host_ip = hosts_map[service.host].ip_address;
  }
}
```

### File I/O with Containers

**✅ Volume Mount File Exchange:**
```javascript
// ✅ CORRECT Pattern for container file I/O
export const performContainerizedScan = async ({ services, project_id }) => {
  const outdir_base = "/penpal-plugin-share";
  const outdir = path.join(outdir_base, "toolname", project_id);
  PenPal.Utils.MkdirP(outdir);
  
  // Create input file on host
  const targets_file = path.join(outdir, `targets-${PenPal.Utils.Epoch()}.txt`);
  const targets = services.map(s => `${s.host_ip}:${s.port}`);
  fs.writeFileSync(targets_file, targets.join('\n'));
  
  // Create output file path
  const output_file = path.join(outdir, `results-${PenPal.Utils.Epoch()}.json`);
  
  // Convert to container paths (volume mount)
  const container_targets = targets_file.replace(outdir_base, "/penpal-plugin-share");
  const container_output = output_file.replace(outdir_base, "/penpal-plugin-share");
  
  // Run tool in container
  const result = await PenPal.Docker.Run({
    image: settings.docker.name,
    cmd: `tool-command -i ${container_targets} -o ${container_output}`,
    daemonize: true,
    volume: { name: "penpal_penpal-plugin-share", path: "/penpal-plugin-share" },
    network: "penpal_penpal"
  });
  
  // Wait for completion and read results
  await PenPal.Docker.Wait(result.stdout.trim());
  const results = fs.readFileSync(output_file, 'utf8');
  return parseResults(results);
};
```

### Plugin Manifest Best Practices

**✅ Development-Ready Manifest:**
```json
{
  "name": "YourPlugin",
  "version": "0.1.0",
  "dependsOn": ["CoreAPI@0.1.0", "Docker@0.1.0", "JobsTracker@0.1.0"],
  "load": false  // Disable during development
}
```

### GraphQL Schema Organization

**✅ Plugin-Specific Schema Structure:**
```
server/graphql/
├── index.js                    // Schema loader
├── resolvers.js               // Resolver structure
├── schema/
│   ├── index.js               // loadGraphQLFiles implementation
│   └── enrichment.schema.graphql  // Plugin-specific types (MUST contain valid GraphQL)
└── resolvers/
    ├── index.js               // Resolver exports
    └── enrichment.default.js  // Plugin resolvers
```

**⚠️ IMPORTANT: GraphQL File Requirements**
- All `.graphql` files MUST contain valid GraphQL definitions (types, queries, mutations, etc.)
- Files with only comments will cause "Unexpected <EOF>" syntax errors
- Remove empty schema files or add minimal valid definitions
- Use specific filenames like `plugin-name-enrichment.schema.graphql` for clarity

**✅ CRITICAL: Correct GraphQL Loading Pattern**
Plugins must follow the established pattern for loading GraphQL files:

```javascript
// ✅ CORRECT: graphql/index.js
export { default as loadGraphQLFiles } from "./schema/index.js";
export { default as resolvers } from "./resolvers.js";

// ❌ WRONG - Don't import from penpal/core
import { loadGraphQLFiles } from "#penpal/core"; // This function doesn't exist
```

**GraphQL Schema Loading Implementation:**
```javascript
// ✅ CORRECT: graphql/schema/index.js
import PenPal from "#penpal/core";
import { dirname, join } from "path";
import { fileURLToPath } from "url";
const __dirname = dirname(fileURLToPath(import.meta.url));
const cur_dir = join(__dirname, ".");

const loadGraphQLFiles = async () => {
  return PenPal.Utils.LoadGraphQLDirectories(cur_dir);
};

export default loadGraphQLFiles;
```

**Resolver Structure:**
```javascript
// ✅ CORRECT: graphql/resolvers.js
import resolvers from "./resolvers/index.js";

export default [
  {
    Query: { ...resolvers.queries },
    Mutation: { ...resolvers.mutations },
    Subscription: { ...resolvers.subscriptions }, // Add subscriptions
  },
  ...resolvers.default_resolvers,
  ...resolvers.scalars,
];
```

**✅ CRITICAL: Plugin Registration Pattern**
Every plugin MUST have an `index.js` file that registers the plugin with PenPal:

```javascript
// ✅ CORRECT: server/index.js
// Overall PenPal coordinating server code
import PenPal from "#penpal/core";

// Plugin-specific info
import Plugin from "./plugin.js";
import Manifest from "./manifest.json" with { type: "json" };

// Register the plugin
PenPal.registerPlugin(Manifest, Plugin);

// ❌ WRONG - Don't export or return anything
export default Plugin; // Remove this line
```

**Key Requirements:**
- Import `PenPal` from `#penpal/core`
- Import `Plugin` from `./plugin.js`
- Import `Manifest` from `./manifest.json` with JSON assertion
- Call `PenPal.registerPlugin(Manifest, Plugin)`
- No exports needed - registration is a side effect

**Plugin Integration:**
```javascript
// ✅ CORRECT: plugin.js
import { loadGraphQLFiles, resolvers } from "./graphql/index.js";

const YourPlugin = {
  loadPlugin() {
    return {
      graphql: {
        types: loadGraphQLFiles,
        resolvers,
      },
    };
  },
};

export default YourPlugin;
```

## Dependency Cycle Resolution

**✅ DataStore Adapter Readiness System**
When plugins depend on DataStore (like Jobs API) but DataStore depends on Docker for databases:

```javascript
// ✅ CORRECT DataStore readiness checking
if (PenPal.DataStore && PenPal.DataStore.AdaptersReady()) {
  // DataStore is ready, use directly
  const job = await PenPal.Jobs.Create(jobData);
} else {
  // DataStore not ready, defer the operation
  await DeferJobCreateOrUpdate(PenPal.Jobs.Create, jobData);
}

// ✅ CORRECT Deferred job system implementation
const DeferJobCreateOrUpdate = (jobsFunction, ...args) => {
  if (PenPal.DataStore && PenPal.DataStore.AdaptersReady()) {
    return jobsFunction(...args);
  } else {
    return new Promise((resolve, reject) => {
      DeferredJobs.queue.push({ function: jobsFunction, args, resolve, reject });
      if (!DeferredJobs.timer) startDeferredJobsTimer();
    });
  }
};

// ❌ WRONG - Circular dependency issues
const job = await PenPal.Jobs.Create(jobData); // May fail if DataStore isn't ready
```

**DataStore Adapter Implementation:**
```javascript
// ✅ CORRECT Adapter readiness implementation
MongoAdapter.isReady = async () => {
  try {
    if (!MongoAdapter.client) return false;
    await MongoAdapter.client.db("admin").command({ ping: 1 });
    return true;
  } catch (error) {
    return false;
  }
};

// ✅ CORRECT Adapter registration with readiness notification
await MongoAdapter.connect();
PenPal.DataStore.RegisterAdapter("MongoAdapter", MongoAdapter);
PenPal.DataStore.SetAdaptersReady(true); // Mark as ready
```

## Common Pitfalls to Avoid

1. **❌ Using non-existent DataStore methods** - Always check CoreAPI usage patterns
2. **❌ Missing plugin/store parameters** - DataStore requires both plugin name and store name
3. **❌ GraphQL type conflicts** - Check for existing types before creating new ones
4. **❌ Incorrect scalar references** - Use existing scalars like `JSON` instead of `JSONObject`
5. **❌ Forgetting timestamps** - Always add `created_at` and `updated_at` fields
6. **❌ Not handling arrays properly** - Use `insertMany()` even for single records
7. **❌ Missing error handling** - Always handle cases where records don't exist
8. **❌ Inconsistent ID generation** - Use `PenPal.Utils.UUID()` for consistent ID format
9. **❌ Hardcoded container paths** - Use volume mount path replacement patterns
10. **❌ Missing Docker dependencies** - Include Docker@0.1.0 for containerized tools
11. **❌ Wrong Jobs API naming** - Use `PenPal.Jobs.Create()` NOT `PenPal.JobsTracker.insertJob()`
12. **❌ Improper job status handling** - Use standardized status constants
13. **❌ Local job management** - Use centralized Jobs API instead of local arrays
14. **❌ Missing host IP resolution** - Enrich services with host data before processing
15. **❌ Inefficient service filtering** - Filter services early to avoid unnecessary processing
16. **❌ Missing volume validation** - Ensure Docker volumes exist and are properly configured
17. **❌ Wrong GraphQL loading pattern** - Don't import `loadGraphQLFiles` from `#penpal/core`
18. **❌ Missing plugin registration** - Every plugin needs `PenPal.registerPlugin()` in `index.js`
19. **❌ Empty GraphQL schema files** - Remove files with only comments, GraphQL requires actual definitions
20. **❌ Circular dependency issues** - Use deferred job system when DataStore adapters aren't ready
21. **❌ Hardcoded status strings** - Use shared constants instead of magic strings
22. **❌ Complex client plugin.js** - Keep client plugins simple, following CoreAPI pattern
23. **❌ Wrong subscription resolver pattern** - Use object resolvers with `subscribe` method, not direct function resolvers
24. **❌ Missing pubsub context validation** - Always check `context?.pubsub` exists before calling `asyncIterator()`
25. **❌ Not checking Docker image readiness** - Always check `PenPal.Docker.IsImageReady()` before running containers since builds are now background

## Shared Constants and Status Management

**✅ CRITICAL: Centralized Constants Pattern**
When developing plugins that share status values, enums, or other constants between client and server, always create a shared constants file in the `common/` directory.

### Creating Shared Constants

**Directory Structure:**
```
Plugins/YourPlugin/
├── client/
│   ├── plugin.js           // Simple pattern - no constants export
│   └── components/
├── server/
│   ├── plugin.js           // Imports and uses constants
│   └── api/
├── common/
│   └── your-constants.js   // Shared constants file
```

**Constants File Pattern:**
```javascript
// ✅ CORRECT: Plugins/YourPlugin/common/your-constants.js
export const YourStatus = {
  PENDING: "pending",
  RUNNING: "running",
  DONE: "done",
  FAILED: "failed",
};

export const STATUS_COLLECTIONS = {
  COMPLETED: [YourStatus.DONE, YourStatus.FAILED],
  ACTIVE: [YourStatus.PENDING, YourStatus.RUNNING],
};

// Helper functions
export const isStatusCompleted = (status) => {
  return STATUS_COLLECTIONS.COMPLETED.includes(status);
};

export const validateStatus = (status) => {
  const validStatuses = Object.values(YourStatus);
  if (!validStatuses.includes(status)) {
    throw new Error(`Invalid status: ${status}. Valid: ${validStatuses.join(", ")}`);
  }
  return status;
};
```

### Server Plugin Integration

**✅ CORRECT: Server plugin imports and exposes constants**
```javascript
// server/plugin.js
import { YourStatus, STATUS_COLLECTIONS, validateStatus } from "../common/your-constants.js";

const YourPlugin = {
  async loadPlugin() {
    // Expose constants through PenPal API
    PenPal.YourAPI = {
      Status: YourStatus,
      StatusCollections: STATUS_COLLECTIONS,
      ValidateStatus: validateStatus,
      // ... other API methods
    };

    return { settings };
  },
};
```

**Server API Usage:**
```javascript
// server/api/index.js
import { YourStatus, STATUS_COLLECTIONS } from "../../common/your-constants.js";

export const updateItem = async (item_id, updates) => {
  // Use constants instead of hardcoded strings
  if (updates.status && !Object.values(YourStatus).includes(updates.status)) {
    throw new Error(`Invalid status: ${updates.status}`);
  }

  // Filter by status using constants
  const activeItems = await PenPal.DataStore.fetch("YourPlugin", "Items", {
    status: { $in: STATUS_COLLECTIONS.ACTIVE }
  });

  return result;
};
```

### Client Component Integration

**✅ CORRECT: Direct import in client components**
```javascript
// client/components/your-component.jsx
import { YourStatus, STATUS_COLLECTIONS, isStatusCompleted } from "../../common/your-constants.js";

const YourComponent = ({ items }) => {
  // Use constants for filtering and comparisons
  const activeItems = items.filter(item => 
    STATUS_COLLECTIONS.ACTIVE.includes(item.status)
  );

  const isComplete = isStatusCompleted(item.status);

  return (
    <div>
      {activeItems.map(item => (
        <div key={item.id}>
          {item.name} - {item.status === YourStatus.RUNNING ? "🔄" : "⏸️"}
        </div>
      ))}
    </div>
  );
};
```

### Client Plugin.js Simplicity

**✅ CORRECT: Keep client plugin.js simple**
```javascript
// ❌ WRONG - Don't export constants or complex APIs from client plugin.js
import { registerPlugin } from "@penpal/core";
import routes from "./routes.js";
import { YourStatus, STATUS_COLLECTIONS } from "../common/your-constants.js";

export { YourStatus, STATUS_COLLECTIONS }; // DON'T DO THIS

export default {
  name: "YourPlugin",
  constants: { YourStatus }, // DON'T DO THIS
  // ... complex plugin API
};

// ✅ CORRECT - Follow CoreAPI pattern exactly
import.meta.glob("./**/*.jsx", { eager: true });
import registerRoutes from "./routes.js";

const YourPlugin = {
  loadPlugin() {
    return {
      registerRoutes,
    };
  },
};

export default YourPlugin;
```

### Migration from Hardcoded Strings

**Common Hardcoded String Patterns to Replace:**
```javascript
// ❌ WRONG - Hardcoded status strings
if (job.status === "done") { /* ... */ }
if (job.status !== "cancelled" && job.status !== "failed") { /* ... */ }
const completedJobs = jobs.filter(j => j.status === "done" || j.status === "failed");

// ✅ CORRECT - Using constants
if (job.status === JobStatus.DONE) { /* ... */ }
if (!COMPLETED_STATUSES.includes(job.status)) { /* ... */ }
const completedJobs = jobs.filter(j => COMPLETED_STATUSES.includes(j.status));
```

**Search and Replace Strategy:**
1. **Find all hardcoded strings**: Use `grep -r '"status_value"' Plugins/YourPlugin/`
2. **Create constants file**: Define all status values and collections
3. **Update server code**: Import constants and replace strings
4. **Update client code**: Import constants and replace strings
5. **Test thoroughly**: Ensure all status comparisons work correctly

### Status Synchronization Best Practices

**✅ Consistent Status Values:**
- Use lowercase, hyphenated strings for status values (`"in-progress"`, not `"InProgress"`)
- Keep status names descriptive but concise
- Avoid status values that could be confused (`"complete"` vs `"done"`)

**✅ Status Collections:**
- Group related statuses into collections (`COMPLETED_STATUSES`, `ACTIVE_STATUSES`)
- Use collections for filtering and validation
- Document what each collection represents

**✅ Helper Functions:**
- Provide validation functions (`validateStatus()`)
- Provide state-checking functions (`isStatusCompleted()`, `isStatusActive()`)
- Include transition logic if needed (`canTransitionTo()`)

### Common Status Management Mistakes

1. **❌ Inconsistent casing**: `"Done"` vs `"done"` vs `"DONE"`
2. **❌ Typos in hardcoded strings**: `"cancelled"` vs `"canceled"`
3. **❌ Magic numbers**: Using `status: 1` instead of named constants
4. **❌ Client-server mismatch**: Different status values on client vs server
5. **❌ Missing validation**: Accepting invalid status values
6. **❌ Complex plugin.js**: Exporting constants through client plugin API
7. **❌ Duplicate definitions**: Defining same constants in multiple files

### Testing Status Management

**✅ Test Status Transitions:**
```javascript
// Test all valid status transitions
const validTransitions = [
  [JobStatus.PENDING, JobStatus.RUNNING],
  [JobStatus.RUNNING, JobStatus.DONE],
  [JobStatus.RUNNING, JobStatus.FAILED],
];

validTransitions.forEach(([from, to]) => {
  test(`Can transition from ${from} to ${to}`, () => {
    expect(canTransitionTo(from, to)).toBe(true);
  });
});
```

**✅ Test Status Collections:**
```javascript
// Ensure collections are mutually exclusive and complete
test('Status collections are properly defined', () => {
  const allStatuses = Object.values(JobStatus);
  const completedStatuses = COMPLETED_STATUSES;
  const activeStatuses = ACTIVE_STATUSES;
  
  // No overlap between active and completed
  const overlap = activeStatuses.filter(s => completedStatuses.includes(s));
  expect(overlap).toHaveLength(0);
  
  // All statuses are categorized
  const categorized = [...activeStatuses, ...completedStatuses];
  expect(categorized.sort()).toEqual(allStatuses.sort());
});
```

By following these patterns, plugins will have consistent, maintainable status management that works reliably across client and server components.
